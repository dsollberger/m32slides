[
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html",
    "title": "01_-_Introductions",
    "section": "",
    "text": "library(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#introducting-the-presenter",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#introducting-the-presenter",
    "title": "01_-_Introductions",
    "section": "Introducting the Presenter",
    "text": "Introducting the Presenter\n\n\n\nLecturer: Derek Sollberger\n\nI go by “Derek” or “teacher”\n\nOriginally from Los Angeles\nBA in Applied Mathematics, UC Berkeley\nMS in Applied Mathematics, CSULB\nMS in Applied Mathematics, UC Merced"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#introducting-the-presenter-1",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#introducting-the-presenter-1",
    "title": "01_-_Introductions",
    "section": "Introducting the Presenter",
    "text": "Introducting the Presenter\n\n\n\n\n\nContinuing Lecturer in Applied Mathematics\n10+ years of teaching at UC Merced\nCourses:\n\nBio 18: Data Science\nBio 175: Biostatistics\nBio 184: Python for Bioinformatics\nMath 32: Probability and Statistics"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#current-research-in-pedagogy",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#current-research-in-pedagogy",
    "title": "01_-_Introductions",
    "section": "Current Research in Pedagogy",
    "text": "Current Research in Pedagogy\n\n\n\n\n\nactive learning\ncomputer programming\naugmented reality"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#on-notetaking",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#on-notetaking",
    "title": "01_-_Introductions",
    "section": "On Notetaking",
    "text": "On Notetaking\n\n\n\nDo not write all of the information from the slides\nDo write along with what Derek writes on the whiteboard\nMake a few notes for main ideas and computer programming\nRetain placement notes, such as “Example #2” or “Survey#1”\nNo need to copy computer code from lecture (code will be provided)"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#why-probability",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#why-probability",
    "title": "01_-_Introductions",
    "section": "Why Probability?",
    "text": "Why Probability?\n\nThe Classic Birthday Problem\nHow many students have to enter the classroom until there are two students that share a birthday?"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#deterministic-vs-probabilistic",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#deterministic-vs-probabilistic",
    "title": "01_-_Introductions",
    "section": "Deterministic vs Probabilistic",
    "text": "Deterministic vs Probabilistic\nDeterministic: a situation that can be solved with equation solving and/or an algorithm\n\nExample: If water boils at 100 degrees Celsius, what is that threshold in Fahrenheit?\n\nProbabilistic: a situation that cannot be completely solved due to an element of chance\n\nExample: What is the chance that it will rain tomorrow?"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#probability-and-you",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#probability-and-you",
    "title": "01_-_Introductions",
    "section": "Probability and You",
    "text": "Probability and You\n\nApplied MathematicsBioengineeringChemical SciencesComputer Science and EngineeringEnvironmental EngineeringMaterials Science and EngineeringMechanical EngineeringPhysics\n\n\nDoes a probabilistic sequence converge or diverge?\n\n\nWhat percentage of lyme disease patients would be cured with the current but experimental treatments?\n\n\nWhat proportion of reactants undergo a reaction early in the reaction?\n\n\nHow many computers in a network would be affected after a virus infection?\n\n\nHow many of a certain species of plants are in the Vernal Pools Reserve?\n\n\nWhat percentage of a semiconductor is made of impurities?\n\n\nFor a commercial passenger airplane, what is the probability that at least two engines fail during a flight?\n\n\nHow many stars are in the Milky Way?"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#ugh-the-syllabus",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#ugh-the-syllabus",
    "title": "01_-_Introductions",
    "section": "Ugh, the Syllabus",
    "text": "Ugh, the Syllabus\n\nDescriptionCLOsPLOs\n\n\nConcepts of probability and statistics. Conditional probability, independence, random variables, distribution functions, descriptive statistics, transformations, sampling errors, confidence intervals, least squares and maximum likelihood. Exploratory data analysis and interactive computing.\n\n\n\nDevelop probabilistic models of random phenomena.\nInfer statistical models from real data.\nApply mathematical methods to probabilistic/statistical models to\n\n\nMake predictions and\nQuantify the uncertainty in these predictions.\n\n\nWrite and run “simple” R programs for the purposes of data analysis, modeling, and visualization.\n\n\n\n\nSolve mathematical problems using analytical methods.\nSolve mathematical problems using computational methods.\nRecognize the relationships between different areas of mathematics and the connections between mathematics and other disciplines.\nGive clear and organized written and verbal explanations of mathematical ideas to a variety of audiences\nModel real-world problems mathematically and analyze those models using their mastery of the core concepts."
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#assessment",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#assessment",
    "title": "01_-_Introductions",
    "section": "Assessment",
    "text": "Assessment\n\nBefore-LectureComputer ProgrammingWritten AssignmentsDiscussionSurveysExams\n\n\n\n5 percent of semester grade\nquizzes due before lecture (i.e. 3 PM on TuTh)\n\nno extensions\n\n5 to 10 minutes per quiz\n\nreview concepts and formulas\npreview thought exercises\n\n\n\n\n\n20 percent of semester grade\nlanguage: R\nplatform: LearnR apps\nanswers to frequently asked questions\n\nno, work may not be done in another language (e.g. Python)\nno, work may not be done in another IDE (e.g. VS Code)\n\n10 to 20 minutes per week\n\n\n\n\n20 percent of semester grade\nclassical math textbook homework\nadvice: do most of the work during your discussion section\n\n\n\n\n10 percent of semester grade for discussion section participation\nTA will track attendance\nadvised to work on written and computer assignments during discussion sections\n\n\n\n\n5 percent of semester grade\ngraded quickly on effort and completion\n5 to 10 minutes per survey\n\n\n\n\nExam 1: 10 percent of semester grade (Tuesday, Sept. 27)\nExam 2: 15 percent of semester grade (Tuesday, Nov. 1)\nFinal Exam: 15 percent of semester grade (date TBD, see survey)"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#student-accessibility-services",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#student-accessibility-services",
    "title": "01_-_Introductions",
    "section": "Student Accessibility Services",
    "text": "Student Accessibility Services\nSpecial Accommodations: University of California, Merced is committed to creating learning environments that are accessible to all. If you anticipate or experience physical or academic barriers based on a disability, please feel welcome to contact me privately so we can discuss options. In addition, please contact Student Accessibility Services (SAS) at (209) 228-6996 or disabilityservices@ucmerced.edu as soon as possible to explore reasonable accommodations. All accommodations must have prior approval from Student Accessibility Services on the basis of appropriate documentation. If you anticipate or experience barriers due to pregnancy, temporary medical condition, or injury,please feel welcome to contact me so we can discuss options. You are encouraged to contact the Dean of Students for support and resources at (209) 228-3633 or https://studentaffairs.ucmerced.edu/dean-students."
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#academic-integrity",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#academic-integrity",
    "title": "01_-_Introductions",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nAcademic integrity is the foundation of an academic community and without it none of the educational or research goals of the university can be achieved. All members of the community are responsible for its academic integrity. Existing policies forbid cheating on examinations, plagiarism and other forms of academic dishonesty. The UC Merced Academic Honesty Policy The UC Merced Academic Honesty Policy can be found on the Student Conduct website. Infractions against academic integrity will incur consequences such as an “F” on the assignment/exam and/or a report to the Academic Senate."
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#nerdy-example",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#nerdy-example",
    "title": "01_-_Introductions",
    "section": "Nerdy Example",
    "text": "Nerdy Example\nHow many numbers between zero and one do we have to add up to have a sum that is greater than one?\n\nAssume selection from a uniform distribution"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#cumulative-summation",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#cumulative-summation",
    "title": "01_-_Introductions",
    "section": "Cumulative Summation",
    "text": "Cumulative Summation\nLet us start with the natural numbers\n\\[i = \\{1, 2, 3, ...\\}\\]\nThen cumulative summation takes place with\n\\[F(n) = \\sum_{i = 1}^{n} i\\]"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#cumulative-summation-1",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#cumulative-summation-1",
    "title": "01_-_Introductions",
    "section": "Cumulative Summation",
    "text": "Cumulative Summation\nIn R, we can define a sequence of natural numbers\n\nnatural_numbers <- 1:10\nprint(natural_numbers)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nand then employ the cumsum() function to perform the cumulative summation.\n\ncumsum(natural_numbers)\n\n [1]  1  3  6 10 15 21 28 36 45 55"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#random-number-generation",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#random-number-generation",
    "title": "01_-_Introductions",
    "section": "Random Number Generation",
    "text": "Random Number Generation\nIn R, we generate a random number between zero and one (here: assumed from a uniform distribution) with the runif function.\n\nrunif(1)\n\n[1] 0.81505\n\n\nFrom there, we can (for example) produce a sample of \\(n = 32\\) such random numbers\n\nrunif(32)\n\n [1] 0.23201307 0.87127077 0.70026832 0.87895876 0.87331526 0.05036756\n [7] 0.70975768 0.04589654 0.81148165 0.67277373 0.36444518 0.05252578\n[13] 0.93071222 0.65069917 0.63382323 0.50296153 0.74808861 0.93567290\n[19] 0.21726304 0.03206728 0.93737557 0.21783477 0.90292332 0.21608644\n[25] 0.31198929 0.27790058 0.42172615 0.43130608 0.20329206 0.94117982\n[31] 0.95907322 0.59290890"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#one-iteration",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#one-iteration",
    "title": "01_-_Introductions",
    "section": "One Iteration",
    "text": "One Iteration\nNext, we employ function composition to apply cumulative summation to our vector of random numbers\n\nX <- cumsum(runif(32))\nprint(X)\n\n [1]  0.2451511  0.5850619  1.2441624  2.0179309  2.5838395  2.9461865\n [7]  3.1303979  3.8536004  4.5735742  4.6358679  4.8938637  5.6998413\n[13]  6.3232469  7.0119696  7.9724195  8.2188149  8.7869916  9.1473904\n[19]  9.8618203 10.3766007 11.3126492 11.9842738 12.1088123 12.6723460\n[25] 13.6674356 14.3986901 15.0511902 15.1968950 16.1945759 16.9695972\n[31] 17.9123227 17.9644575\n\n\nand then we can check when our cumulative summation first exceeded 1.0\n\nwhich.max(X > 1.0)\n\n[1] 3"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#simulation",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#simulation",
    "title": "01_-_Introductions",
    "section": "Simulation",
    "text": "Simulation\nTo try to understand the randomness, we can repeat the procedure for many iterations (here, \\(N = 10000\\)).\n\nN <- 1e5 #number of iterations\nour_results <- rep(NA, N) #initialize space for results\nfor(i in 1:N){\n  this_vector <- cumsum(runif(10))\n  this_result <- which.max(this_vector > 1.0)\n  our_results[i] <- this_result\n}"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#visualization",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#visualization",
    "title": "01_-_Introductions",
    "section": "Visualization",
    "text": "Visualization\nTo understand a distribution of a probabilistic setting, we can visualize the results.\n\nCodeGraph\n\n\n\ndf <- data.frame(our_results)\ndf |>\n  ggplot() +\n  geom_histogram(aes(x = our_results), binwidth = 1,\n                 color = \"black\", fill = \"blue\") +\n  labs(title = \"Histogram of Results\",\n       subtitle = \"How would you describe the distribution?\",\n       caption = \"Math 32\",\n       x = \"number of numbers needed\",\n       y = \"count\") +\n  scale_x_continuous(breaks = seq(2,8))"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#measure-of-centrality",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#measure-of-centrality",
    "title": "01_-_Introductions",
    "section": "Measure of Centrality",
    "text": "Measure of Centrality\nTo hone in on our understanding of the distribution, let us take the mean() of our_results\n\nmean(our_results, na.rm = TRUE)\n\n[1] 2.71847\n\n\n\nNote: R stops execution upon evaluating a missing value. For our intents and purposes, we will suppress that exception with na.rm = TRUE"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#nerdy-example-1",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#nerdy-example-1",
    "title": "01_-_Introductions",
    "section": "Nerdy Example",
    "text": "Nerdy Example\nHow many numbers between zero and one do we have to add up to have a sum that is greater than one?\n\\[ e \\approx 2.718282\\]\n\n# theoretical answer\nexp(1)\n\n[1] 2.718282\n\n\nThought questions:\n\nhow do we know that the answer converges?\nhow many iterations did we need for a sufficient answer?"
  },
  {
    "objectID": "posts/01_-_Introduction/Math_32_-_Introductions.html#looking-ahead",
    "href": "posts/01_-_Introduction/Math_32_-_Introductions.html#looking-ahead",
    "title": "01_-_Introductions",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\nBe mindful of before-lecture quizzes\n\ndue Fri., Aug. 26:\n\nFinal Exam Date (survey)\nSoftware Installation\n\n\nExam 1 will be on Tues., Sept. 27"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math 32",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "m32slides",
    "section": "",
    "text": "Oct 4, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 6, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 25, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html",
    "title": "02_-_Independence",
    "section": "",
    "text": "library(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#starter-examples",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#starter-examples",
    "title": "02_-_Independence",
    "section": "Starter Examples",
    "text": "Starter Examples\nIn order to introduce probability concepts, you will notice that many sections of this book start out by talking about simple situations such as flipping a coin or rolling a die (or rolling a pair of dice). This is to ease the reader into more complicated examples.\n\n\n\n\n\n\nNote\n\n\n\nA possibility space is a set of all of the possible outcomes."
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-1-one-die",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-1-one-die",
    "title": "02_-_Independence",
    "section": "Example 1: One Die",
    "text": "Example 1: One Die\n\n\nConsider rolling one six-sided die. For each of the following events, list their possible ways, and then find their probabilities:\n\nA: rolling an even number\nB: rolling a number greater than 3\nC: rolling a double-digit number\n\n\n\n\n\none, six-sided die"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#starting-to-combine",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#starting-to-combine",
    "title": "02_-_Independence",
    "section": "Starting to Combine",
    "text": "Starting to Combine\nAt first, we consider simply adding up the probabilities to compute the probability of the union of the probabilities:\n\\[P(A \\cup B) = P(A) + P(B) = ?\\]"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#inconsistent",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#inconsistent",
    "title": "02_-_Independence",
    "section": "Inconsistent?",
    "text": "Inconsistent?\nSo far,\n\\[P(A \\cup B) = P(A) + P(B) = 100\\%\\]\nWhat went wrong? (Discuss with a neighbor)"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#some-set-notation",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#some-set-notation",
    "title": "02_-_Independence",
    "section": "Some Set Notation",
    "text": "Some Set Notation\n\n\n\n\n\n\nTip\n\n\n\nThe union of sets A and B is the set of all elements that appear either in set A OR set B\n\\[A \\cup B = \\{x : x \\in A \\text{ OR } x \\in B\\}\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe intersection of sets A and B is the set of all elements that appear both in set A AND set B\n\\[A \\cap B = \\{x : x \\in A \\text{ AND } x \\in B\\}\\]"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#inclusion-exclusion-principle",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#inclusion-exclusion-principle",
    "title": "02_-_Independence",
    "section": "Inclusion-Exclusion Principle",
    "text": "Inclusion-Exclusion Principle\nWe observe that there was an overlap in the calculation. Since some elements were counted twice, we can compensate by subtracting one copy of that overlap. This notion is called the Inclusion-Exclusion Principle\n\n\n\n\n\n\nNote\n\n\n\nTo compute the probability of a set union, we need to consider the overlapping portions. For two sets A and B, the probability of observing the union is\n\\[P(A \\cup B) = {\\color{red}P(A)} + {\\color{blue}P(B)} - {\\color{purple}P(A \\cap B)}\\]"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-2-two-dice",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-2-two-dice",
    "title": "02_-_Independence",
    "section": "Example 2: Two dice",
    "text": "Example 2: Two dice\n\n\nConsider rolling two six-sided dice. Find the probability that their total is 8 or the second die shows a number greater or equal to 5.\n\n\n\n\ntwo dice"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#subtlety-in-assumptions",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#subtlety-in-assumptions",
    "title": "02_-_Independence",
    "section": "Subtlety in Assumptions",
    "text": "Subtlety in Assumptions\nIn the previous example, we assumed a notion of sampling with replacement. That is, when rolling dice, we know that a number can be repeated. In other situations were observations cannot repeat, we are sampling without replacement."
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-3-faculty-matters",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-3-faculty-matters",
    "title": "02_-_Independence",
    "section": "Example 3: Faculty Matters",
    "text": "Example 3: Faculty Matters\n\nPromptSample Space 1Sample Space 2\n\n\nConsider a subset of the UC Merced Applied Math department with 6 faculty members—Blanchette, Buvoli, Sandoval, Stepanian, Thompson, Yatskar—must select two of its members to serve on a personnel review committee. Because the work will be time-consuming, no one is anxious to serve, so it is decided that the representatives will be selected by putting 6 slips of paper in a box, mixing them, and selecting two without replacement.\n\nWhat is the probability that both Thompson and Yatskar will be selected?\nWhat is the probability that at least one of the two members whose name begins with ‘B’ is selected?\nIf the 6 faculty members have taught for 15, 3, 5, 9, 4, and 12 years, respectively, at the university, what is the probability that the two chosen representatives have at least a combined 10 years’ teaching experience at the university?"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#assuming-a-distribution",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#assuming-a-distribution",
    "title": "02_-_Independence",
    "section": "Assuming a Distribution",
    "text": "Assuming a Distribution\nUnless otherwise noted, the coin flip has two disjoint outcomes—heads or tails—with probabilities\n\\[P(\\text{heads}) = 0.5, \\quad P(\\text{tails}) = 0.5\\]\n\nIn the early formation of the field of statistics, there were considerations such as the following. How should the possibility space for a trial of flipping two coins be represented?\n\n3 elements: \\(\\{\\)two heads, mixed result, two tails\\(\\}\\), OR\n4 elements: \\(\\{\\)HH, HT, TH, TT\\(\\}\\)"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#complements",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#complements",
    "title": "02_-_Independence",
    "section": "Complements",
    "text": "Complements\n\n\n\n\n\n\nNote\n\n\n\nTo sets are disjoint if\n\\[P(A \\cap B) = 0\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\nA possibility space is a set of all of the possible outcomes for an event. It is usually denoted by the Greek letter capital omega.\n\n\nFor example, the set of all outcomes for two coin flips of a fair coin turns out to be\n\\[\\Omega = \\{HH, HT, TH, TT\\}\\]\n\n\n\n\n\n\nNote\n\n\n\nIf \\(A\\) is a set (and a subset of the possibility space), then the complement of A, denoted \\(A^{c}\\), is the set of outcomes that is in the universal set but not in the set A\n\\[A \\subseteq \\Omega \\quad\\Rightarrow\\quad A^{c} = \\Omega - A\\]"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-4-one-die",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-4-one-die",
    "title": "02_-_Independence",
    "section": "Example 4: One Die",
    "text": "Example 4: One Die\n\n\n\n\nFor example, if we think of our roll of a six-sided die, the possibility space was\n\\[\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\]\nIf we have a subset consisting of the even numbers\n\\[E = \\{2, 4, 6\\}\\]\nwhat do you think the complement \\(E^{c}\\) will be?"
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#empty-set",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#empty-set",
    "title": "02_-_Independence",
    "section": "Empty Set",
    "text": "Empty Set\n\n\n\n\n\n\nNote\n\n\n\nThe empty set \\(\\{\\}\\) literally has zero elements in the set\n\n\nClaim: Set \\(A\\) and its complement are disjoint."
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-5-replacement",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#example-5-replacement",
    "title": "02_-_Independence",
    "section": "Example 5: Replacement",
    "text": "Example 5: Replacement\nThere may be situations where we need to be careful about whether selections from a set were done with replacement or without replacement.\nIn the wardrobe, there are 8 blue socks and 6 red socks.\n\\[B, B, B, B, B, B, B, B\\]\n\\[R, R, R, R, R, R\\]\nCompute the following probabilities\n\nSelecting 3 red socks with replacement\nSelecting 3 red socks without replacement\nSelecting 4 blue socks with replacement\nSelecting 4 blue socks without replacement\n\n\n\n\n\n\n\nTip\n\n\n\nNotice how when we sample with replacement, each iteration is independent of the previous iterations. When we sample without replacement, each iteration depends on the previous iterations."
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#de-morgans-law",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#de-morgans-law",
    "title": "02_-_Independence",
    "section": "De Morgan’s Law",
    "text": "De Morgan’s Law\nOne relationship between the notions of complements, intersections, and unions is as follows.\n\n\n\n\n\n\nNote\n\n\n\n\\[(A \\cup B)^{c} = A^{c} \\cap B^{c}\\]\nThe complement of the union is the intersection of the complements."
  },
  {
    "objectID": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#looking-ahead",
    "href": "posts/02_-_Independence/Math_32_-_02_-_Independence.html#looking-ahead",
    "title": "02_-_Independence",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 2:\n\nWHW1\nLHW1\nCLO (survey)\n\nBe mindful of before-lecture quizzes\n\nExam 1 will be on Tues., Sept. 27\n\n\n\n\nRafa Moral\n\n\n40-second song"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#example-subsetting",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#example-subsetting",
    "title": "Dependence",
    "section": "Example: Subsetting",
    "text": "Example: Subsetting\nConsider the months of the year\n\\[M = \\{\\text{Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec} \\}\\]\nLet us say that a month is ``long’’ if it has 31 days. What is the probability that we have a long month given that we are in the Fall semester?\n\\[F = \\{ \\text{Aug, Sep, Oct, Nov, Dec} \\}\\]"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#conditional-probability",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#conditional-probability",
    "title": "Dependence",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nWe can condense this process into a formula for conditional probability:\n\n\n\n\n\n\nNote\n\n\n\nThe conditional probability of observing event \\(A\\) given event \\(B\\) has already taken place is\n\\[P(A|B) = \\displaystyle\\frac{P(A \\cap B)}{P(B)}\\]"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#example-contigency-tables",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#example-contigency-tables",
    "title": "Dependence",
    "section": "Example: Contigency Tables",
    "text": "Example: Contigency Tables\nIn this hypothetical example, suppose that we are following an epidemiologist who is testing patients at a hospital in for the novel strain of coronavirus.\n\nBuild a contingency table with the following data\n\n\n175 true positives\n32 false negatives\n18 false positives\n2019 true negatives\n\n\nCompute the probability that a randomly selected patient is disease free given that the drug test is positive."
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#prosecutors-fallacy",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#prosecutors-fallacy",
    "title": "Dependence",
    "section": "Prosecutor’s Fallacy",
    "text": "Prosecutor’s Fallacy\n\nUsing the same counts as the previous example, compute the probability that for a randomly selected patient the test returns positive given that the patient is disease free.\n\n\n\n\n\n\n\nWarning\n\n\n\nConverses for conditional probability are almost never equal.\n\\[P(A|B) \\neq P(B|A)\\]"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#bayes-rule",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#bayes-rule",
    "title": "Dependence",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\nIn the previous section, we studied conditional probability\n\\[P(B|A) = \\displaystyle\\frac{P(A \\text{ and } B)}{P(A)}\\]\nand we talked about how the inverse probabilities \\(P(A|B)\\) and \\(P(B|A)\\) are almost never equal. In this section, we discuss how to properly think and calculate that inverse probability.\n\n\n\n\n\n\nTip\n\n\n\nAnother look at conditional probability is\n\\[P(A \\text{ and } B) = P(B|A) \\cdot P(A)\\]\nThis is read as “The probability of the intersection \\(A\\) and \\(B\\) is the probability of event \\(B\\) conditioned on event \\(A\\).”\n\n\n\n\n\n\n\n\nTip\n\n\n\nMoreover, if we consider how if event \\(B\\) is dependent on event \\(A\\), then sometimes \\(B\\) happens when \\(A\\) happens and sometimes when \\(A\\) does not occur. More succinctly, the total probability of event \\(B\\) is\n\\[P(B) = P(B|A) \\cdot P(A) + P(B|A^{c}) \\cdot P(A^{c})\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\nStaring with the conditional probability formula\n\\[P(B|A) = \\displaystyle\\frac{P(A \\text{ and } B)}{P(A)}\\]\nBayes’ Rule combines the ideas of conditioned probability and total probability as\n\\[P(A|B) = \\displaystyle\\frac{P(A \\text{ and } B)}{P(B)} = \\displaystyle\\frac{P(B|A) \\cdot P(A)}{P(B|A) \\cdot P(A) + P(B|A^{c}) \\cdot P(A^{c})}\\]"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#a-deep-dive",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#a-deep-dive",
    "title": "Dependence",
    "section": "A Deep Dive",
    "text": "A Deep Dive\n\nExampleTree DiagramNumeratorDenominator\n\n\nAn executive has their blood tested for boneitis. Let \\(B\\) be the event that an executive has the disease, and let \\(T\\) be the event that the test returns positive. Laboratory trials yielded the following information:\n\\[P(T|B) = 0.70 \\quad\\text{and}\\quad P(T|B^{c}) = 0.10\\]\nAssume a prior probability of \\(P(B) = 0.0032\\). Compute \\(P(B|T)\\)\n\n\n\n\n\ntree diagram\n\n\n\n\n\n\n\ntree diagram\n\n\n\n\n\n\n\ntree diagram"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#more-practice",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#more-practice",
    "title": "Dependence",
    "section": "More Practice",
    "text": "More Practice\n\nExampleTree DiagramNumeratorDenominator\n\n\nAn executive has their blood tested for boneitis. Let \\(B\\) be the event that an executive has the disease, and let \\(T\\) be the event that the test returns positive. Laboratory trials yielded the following information:\n\\[P(T|B) = 0.70 \\quad\\text{and}\\quad P(T|B^{c}) = 0.10\\]\nAssume a prior probability of \\(P(B) = 0.0032\\). Compute \\(P(B|T^{c})\\)\n\n\n\n\n\ntree diagram\n\n\n\n\n\n\n\ntree diagram\n\n\n\n\n\n\n\ntree diagram"
  },
  {
    "objectID": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#looking-ahead",
    "href": "posts/03_-_Dependence/Math_32_-_03_-_Dependence.html#looking-ahead",
    "title": "Dependence",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 2:\n\nWHW1\nLHW1\nCLO (survey)\n\nBe mindful of before-lecture quizzes\nNo discussions next week for Math 32 (Sept. 5-7)\nExam 1 will be on Tues., Sept. 27\n\n\n\n\n\nsong about Bayes’ Rule"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-spam-filtering",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-spam-filtering",
    "title": "Bayes’ Rule (Examples)",
    "section": "Example: Spam Filtering",
    "text": "Example: Spam Filtering\nIn 2002, Paul Graham used Bayes’ Rule as part of his algorithms to greatly decrease false positive rates of unwanted e-mails (“spam”). Let \\(H^{c}\\) be the event that an e-mail is “spam”. Let \\(W\\) be the event that an e-mail contains a trigger word such as “watches”. Suppose that\n\nthe probability that an e-mail contains that word given that it is spam is 17%\nthe probability that an e-mail contains that word given that it is not spam is 9%\nthe probability that a randomly selected e-mail message is spam is 80%\n\nFind the probability that an e-mail message is spam, given that the trigger word appears."
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-quality-control",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-quality-control",
    "title": "Bayes’ Rule (Examples)",
    "section": "Example: Quality Control",
    "text": "Example: Quality Control\nA manufacturing process produces integrated circuit chips. Over the long run the fraction of bad chips produced by the process is around 20%. Thoroughly testing a chip to determine whether it is good or bad is rather expensive, so a cheap test is tried. All good chips will pass the cheap test, but so will 10% of the bad chips. Given that a chip passes the test, what is the probability that the chip was defective?"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-monty-hall-problem",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-monty-hall-problem",
    "title": "Bayes’ Rule (Examples)",
    "section": "Example: Monty Hall Problem",
    "text": "Example: Monty Hall Problem\n\n\n\n\nMonty Hall asks you to choose one of three doors. One of the doors hides a prize and the other two doors have no prize. You state out loud which door you pick, but you don’t open it right away.\n“Monty opens one of the other two doors, and there is no prize behind it.\n“At this moment, there are two closed doors, one of which you picked. The prize is behind one of the closed doors, but you don’t know which one. Monty asks you, ‘Do you want to switch doors?’”\n\nswitch doors\ndo not switch doors"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-dui-checkpoint",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-dui-checkpoint",
    "title": "Bayes’ Rule (Examples)",
    "section": "Example: DUI Checkpoint",
    "text": "Example: DUI Checkpoint\nA breath analyzer, used by the police to test whether drivers exceed the legal limit set for the blood alcohol percentage while driving, is known to satisfy\n\\[P(A|B) = P(A^{c}|B^{c}) = x\\]\nwhere \\(A\\) is the event “breath analyzer indicates that legal limit is exceeded” and \\(B\\) “driver’s blood alcohol percentage exceeds legal limit.” On Saturday nights, about 4% of the drivers are known to exceed the limit.\n\nDescribe in words the meaning of \\(P(B|A)\\)\nDetermine \\(P(B|A)\\) if \\(x = 0.90\\)\nHow big should \\(x\\) be so that \\(P(B|A) \\geq 0.95\\)?"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-disease-outbreak",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#example-disease-outbreak",
    "title": "Bayes’ Rule (Examples)",
    "section": "Example: Disease Outbreak",
    "text": "Example: Disease Outbreak\nSuppose that at UC Merced, there is a two percent chance that a freshman has herpes at the end of the school year. Let \\(H\\) be the event of having the virus, while \\(C\\) represents the event that the freshman is from the Cathedral dorm. Among the herpes carriers, the probably of being a Cathedral resident is 32%. Among those free of disease, the probably of being a Cathedral resident is 13%. What is the probability that a freshman has herpes, given that you know that he or she lived in the Cathedral dorm?"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#generalized-bayes-rule",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#generalized-bayes-rule",
    "title": "Bayes’ Rule (Examples)",
    "section": "Generalized Bayes’ Rule",
    "text": "Generalized Bayes’ Rule\nIf we are conditioning \\(B\\) on an event \\(A\\), where the latter can be partitioned into several subsets,\n\\[A = \\{ A_{1}, A_{2}, ..., A_{j} \\}\\]\nthen the total probability is\n\\[P(B) = P(B|A_{1}) \\cdot P(A_{1}) + P(B|A_{2}) \\cdot P(A_{2}) + ... + P(B|A_{n}) \\cdot P(A_{n})\\]\nand Bayes Rule for computing the probability of \\(A_{i}\\) given \\(B\\) becomes\n\\[P(A_{i}|B) = \\displaystyle\\frac{ P(B|A_{i}) \\cdot P(A_{i}) }{ P(B|A_{1}) \\cdot P(A_{1}) + P(B|A_{2}) \\cdot P(A_{2}) + ... + P(B|A_{n}) \\cdot P(A_{n}) }\\]"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#bayesian-odds",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#bayesian-odds",
    "title": "Bayes’ Rule (Examples)",
    "section": "Bayesian Odds",
    "text": "Bayesian Odds\n\n\n\n\n\n\nNote\n\n\n\nThe Bayesian odds of event \\(A\\) to event \\(B\\) given that event \\(C\\) has already taken place is\n\\[\\displaystyle\\frac{ P(A|C) }{ P(B|C) }\\]"
  },
  {
    "objectID": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#looking-ahead",
    "href": "posts/04_-_Bayes Rule/Math_32_-_04_-_Dependence.html#looking-ahead",
    "title": "Bayes’ Rule (Examples)",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 9:\n\nWHW2\nLHW2\nPerceptions of Probability (survey)\n\nBe mindful of before-lecture quizzes\nNo discussions this week for Math 32 (Sept. 5-7)\nExam 1 will be on Tues., Sept. 27\n\n\n\nsource"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#review-summation-notation",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#review-summation-notation",
    "title": "05: Measures of Centrality",
    "section": "Review: Summation Notation",
    "text": "Review: Summation Notation\nThe Fibonnaci Sequence \\(\\{1, 1, 2, 3, 5, 8, 13, ...\\}\\) is an example of a sequence where\n\\(F_{1} = 1, F_{2} = 1, F_{n} = F_{n-1} + F_{n-2}\\)\nCompute\n\n\\(\\displaystyle\\sum_{i=1}^{1} a_{i}\\)\n\\(\\displaystyle\\sum_{i=1}^{2} a_{i}\\)\n\\(\\displaystyle\\sum_{i=1}^{3} a_{i}\\)\n\\(\\displaystyle\\sum_{i=1}^{4} a_{i}\\)"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#populations-versus-samples",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#populations-versus-samples",
    "title": "05: Measures of Centrality",
    "section": "Populations versus Samples",
    "text": "Populations versus Samples\nWe tend to study a relatively small sample to understand the behavior of a much larger population."
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#mean-average",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#mean-average",
    "title": "05: Measures of Centrality",
    "section": "Mean (Average)",
    "text": "Mean (Average)\n\n“mean” and “average” are synonymous and will be used interchangably\nThe mean of \\(\\{ x_{1}, x_{2}, ..., x_{n} \\}\\) is denoted by\n\nGreek letter \\(\\mu\\) (“mu”) for a population mean (where we know all of the elements)\nAnglicized \\(\\bar{x}\\) (“x bar”) for a sample mean (where we are working with a sample of data)\n\nTo calculate the mean\n\nAdd up all of the numbers\nDivide by the amount of numbers\n\n\n\\[\\mu = \\displaystyle\\frac{1}{N}\\displaystyle\\sum_{i=1}^{N} x_{i} \\quad\\text{or}\\quad \\bar{x} = \\displaystyle\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n} x_{i}\\]"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#example-one-die",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#example-one-die",
    "title": "05: Measures of Centrality",
    "section": "Example: One Die",
    "text": "Example: One Die\n\nFind the mean of the roll of one six-sided die.\nFind the mean of the sample \\(\\{21, 22, 23, 32\\}\\)."
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#median",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#median",
    "title": "05: Measures of Centrality",
    "section": "Median",
    "text": "Median\nThe median of an ordered, discrete set of numbers is the number in the middle. If there are an even amount of data, then the median is the average of the middle two numbers in the ordered data set.\n\nCompute the median of \\(\\{1, 2, 1, 5, 3\\}\\)\nCompute the median of \\(\\{1, 1, 2, 3, 5, 8\\}\\)"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#weighted-mean",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#weighted-mean",
    "title": "05: Measures of Centrality",
    "section": "Weighted Mean",
    "text": "Weighted Mean\n\\[\\bar{x} = \\displaystyle\\frac{ \\displaystyle\\sum_{i=1}^{n} {\\color{red}w_{i}} \\cdot {\\color{blue}x_{i}}  }{ \\displaystyle\\sum_{i=1}^{n} {\\color{red}w_{i}} }\\]"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#example-cal-kulas",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#example-cal-kulas",
    "title": "05: Measures of Centrality",
    "section": "Example: Cal Kulas",
    "text": "Example: Cal Kulas\n\n\n\nSetting\nGoing into the final exam for a Statistics course, Cal Kulas had earned the following marks in the other categories.\n\n\n\n\n\nCategory\n\n\nWeight\n\n\nCal Kulas\n\n\n\n\n\n\nattendance\n\n\n10%\n\n\n95%\n\n\n\n\nquizzes\n\n\n20%\n\n\n75%\n\n\n\n\nmidterms\n\n\n25%\n\n\n60%\n\n\n\n\nproject\n\n\n20%\n\n\n90%\n\n\n\n\n\n\n\n\nTasks\n\nWhat is his current grade in the course?\nWhat does Cal Kulas need on the final exam so that he earns at least 80% in the course?"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#review-summation-notation-1",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#review-summation-notation-1",
    "title": "05: Measures of Centrality",
    "section": "Review: Summation Notation",
    "text": "Review: Summation Notation\nThe Fibonnaci Sequence \\(\\{1, 1, 2, 3, 5, 8, 13, ...\\}\\) is an example of a sequence where\n\\(F_{1} = 1, F_{2} = 1, F_{n} = F_{n-1} + F_{n-2}\\)\nCompute\n\n\\(\\displaystyle\\prod_{i=1}^{1} a_{i}\\)\n\\(\\displaystyle\\prod_{i=1}^{2} a_{i}\\)\n\\(\\displaystyle\\prod_{i=1}^{3} a_{i}\\)\n\\(\\displaystyle\\prod_{i=1}^{4} a_{i}\\)"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#for-formulas",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#for-formulas",
    "title": "05: Measures of Centrality",
    "section": "For Formulas",
    "text": "For Formulas\nIn particular, sigma and product notation will allow us to express probability formulas more efficiently. For example, the independence formula for two events \\(A\\) and \\(B\\),\n\\[P(AB) = P(A) \\cdot P(B)\\]\nbecomes the following for \\(n\\) independent events:\n\\[P\\left(  \\{X_{i}\\}_{i=1}^{n} \\right) = \\displaystyle\\prod_{i=1}^{n} P(X_{i})\\]"
  },
  {
    "objectID": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#looking-ahead",
    "href": "posts/05_-_Measures of Centrality/Math_32_05_Centrality.html#looking-ahead",
    "title": "05: Measures of Centrality",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 9:\n\nWHW2\nLHW2\nPerceptions of Probability (survey)\n\nBe mindful of before-lecture quizzes\nExam 1 will be on Tues., Sept. 27\n\n\n\n\n\nEven NASA makes mistakes!\n\n\nsource"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#overview",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#overview",
    "title": "06: Variance",
    "section": "Overview",
    "text": "Overview\n\\[s^{2} = \\displaystyle\\frac{1}{n-1}\\displaystyle\\sum_{i = 1}^{n} (x_{i} - \\bar{x})^{2}\\]\nToday’s main questions are “What is variance and what is a standard deviation?” We will go through\n\nthe formulas and calculations\ndemostrations\napplications (word problems)"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#notation",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#notation",
    "title": "06: Variance",
    "section": "Notation",
    "text": "Notation\n\n\n\n\nWe tend to study a relatively small sample to understand the behavior of a much larger population."
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#example-nathans-hot-dog-eating-contest",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#example-nathans-hot-dog-eating-contest",
    "title": "06: Variance",
    "section": "Example: Nathan’s Hot Dog Eating Contest",
    "text": "Example: Nathan’s Hot Dog Eating Contest\n\n\nEach year on July 4, the Nathan’s Hot Dog Eating Contest takes place on Coney Island in New York. The rule is simple: eat as many hot dogs (and buns) as you can in 10 minutes. The past 5 winning amounts were: 63, 70, 72, 74, 71. Compute the variance.\n\n\n\nsource\n\n\n\n\n\n\nwinners Joey Chestnut and Miki Sudo"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#units",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#units",
    "title": "06: Variance",
    "section": "Units?",
    "text": "Units?\n\n\n\nsquare hot dogs?"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#demostrations",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#demostrations",
    "title": "06: Variance",
    "section": "Demostrations",
    "text": "Demostrations\n\nSetupRA to BC to D\n\n\nFor each of the following sets\n\n\\(A = \\{1, 2, 3, 4, 5, 6, 7\\}\\)\n\\(B = \\{3, 4, 5, 6, 7, 8, 9\\}\\)\n\\(C = \\{-3, -2, -1, 0, 1, 2, 3\\}\\)\n\\(D = \\{-9, -6, -3, 0, 3, 6, 9\\}\\)\n\nwe will compute the sample mean, sample median, and sample standard deviation.\n\n\n\nA <- seq(1, 7, 1)\nB <- A + 2\nC <- seq(-3, 3, 3)\nD <- 3*C\n\n\n\n\nmean(A)\n\n[1] 4\n\nmean(B)\n\n[1] 6\n\n\n\nmedian(A)\n\n[1] 4\n\nmedian(B)\n\n[1] 6\n\n\n\nsd(A)\n\n[1] 2.160247\n\nsd(B)\n\n[1] 2.160247\n\n\n\n\n\nmean(C)\n\n[1] 0\n\nmean(D)\n\n[1] 0\n\n\n\nmedian(C)\n\n[1] 0\n\nmedian(D)\n\n[1] 0\n\n\n\nsd(C)\n\n[1] 3\n\nsd(D)\n\n[1] 9"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#shiny",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#shiny",
    "title": "06: Variance",
    "section": "Shiny",
    "text": "Shiny\n\n# https://quarto.org/docs/interactive/shiny/\nsliderInput(\"mu\", \"mean:\", \n            min = 1, max = 10, value = 5)\nsliderInput(\"s\", \"deviation:\", \n            min = 1, max = 5, value = 2)\nplotOutput(\"distPlot\")\n\n\noutput$distPlot <- renderPlot({\n  x <- rnorm(100, mean = mu, sd = s)\n  df <- data.frame(x = x)\n  \n  df |>\n    ggplot(aes(x = x)) +\n    geom_density()\n})"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#standardization",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#standardization",
    "title": "06: Variance",
    "section": "Standardization",
    "text": "Standardization\n\\[z = \\displaystyle\\frac{x - \\mu}{\\sigma}\\]\nTo standardize data, compute a z-score by\n\nsubtracting by the mean\nthen dividing by the standard deviation\n\nThis calculation is considered to be “unitless”, and the units are usually said as “[number of] standard deviations above/below the mean”\nMost data falls within two standard deviations of the mean,\n\\[\\text{usually } z \\in (-2, 2)\\]\nbut \\(z \\in (-\\infty, \\infty)\\)"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#example-dating-website-data",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#example-dating-website-data",
    "title": "06: Variance",
    "section": "Example: Dating Website Data",
    "text": "Example: Dating Website Data\n\nScenario 1Scenario 2\n\n\n\nAccording to OkCupid data, if men rate women on a scale from 1 = “least attractive” to 7 = “most attractive”, the average score is 3.99 with a sample standard deviation of 1.6401.\n\nWhat is the \\(z\\)-score of a woman rated a “6”?\nWhat is the attractiveness score of a woman at a \\(z\\)-score of 1.5?\n\n\n\n\nAccording to OkCupid data, if women rate men on a scale from 1 = “least attractive” to 7 = “most attractive”, the average score is 2.43 with a sample standard deviation of 1.2510.\n\nWhat is the \\(z\\)-score of a woman rated a “6”?\nWhat is the attractiveness score of a woman at a \\(z\\)-score of 1.5?"
  },
  {
    "objectID": "posts/06_-_Variance/Math_32_06_Variance.html#looking-ahead",
    "href": "posts/06_-_Variance/Math_32_06_Variance.html#looking-ahead",
    "title": "06: Variance",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 16:\n\nWHW3\nLHW3\nDemographics Part 1 (survey)\n\nBe mindful of before-lecture quizzes\nExam 1 will be on Tues., Sept. 27\n\nmore information in weekly announcements\n\n\n\n\nsource"
  },
  {
    "objectID": "posts/07_-_Expectation/Math_32_07_Expectation.html#example-demographics",
    "href": "posts/07_-_Expectation/Math_32_07_Expectation.html#example-demographics",
    "title": "07: Expectation",
    "section": "Example: Demographics",
    "text": "Example: Demographics\n\nSuppose that all of the students in Math 32 are between ages 19 and 21 inclusively with the following distribution:\n\nAge 19: 35%\nAge 20: 45%\nAge 21: 20%\n\nRewrite the data as a discrete mass function."
  },
  {
    "objectID": "posts/07_-_Expectation/Math_32_07_Expectation.html#discrete-probability-distributions",
    "href": "posts/07_-_Expectation/Math_32_07_Expectation.html#discrete-probability-distributions",
    "title": "07: Expectation",
    "section": "Discrete Probability Distributions",
    "text": "Discrete Probability Distributions\n\n\n\n\n\n\nNote\n\n\n\nA discrete probability distribution is a population where we can list the possible values\n\\[X = \\{ x_{1}, x_{2}, x_{3}, ... x_{n} \\}\\]\nand measure the respective probabilities\n\\[P(X = x_{1}), P(X = x_{2}), P(X = x_{3}), ..., P(X = x_{n})\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs usual, the probabilities rules include that each probability is between zero and one inclusively\n\\[0 \\leq P(X = x_{i}) \\leq 1\\]\nand that all probabilities add up to 100 percent\n\\[\\displaystyle\\sum_{x \\in X} P(X = x) = 1\\]"
  },
  {
    "objectID": "posts/07_-_Expectation/Math_32_07_Expectation.html#expectation",
    "href": "posts/07_-_Expectation/Math_32_07_Expectation.html#expectation",
    "title": "07: Expectation",
    "section": "Expectation",
    "text": "Expectation\n\n\n\n\n\n\nNote\n\n\n\nFor a random variable \\(X\\) (understood through a discrete probability distribution), its expected value is\n\\[\\mu = \\text{E}[{\\color{blue}X}] = \\displaystyle\\sum_{x \\in X} {\\color{blue}x} \\cdot {\\color{red}P(X = x)}\\]\n\n\n\nCompute the expected value of the roll of one six-sided die."
  },
  {
    "objectID": "posts/07_-_Expectation/Math_32_07_Expectation.html#variance",
    "href": "posts/07_-_Expectation/Math_32_07_Expectation.html#variance",
    "title": "07: Expectation",
    "section": "Variance",
    "text": "Variance\n\n\n\n\n\n\nNote\n\n\n\nThe variance of a random variable \\(X\\) is defined as the expected squared deviation from the mean\n\\[\\text{Var}(X) = \\text{E}[(X - \\text{E}[X])^{2}]\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe above theoretical formula is built from first principles and is good for building the math foundation. However, the following practical formula is better for hand calculations and computer calculations.\n\n\nClaim:\n\\[\\text{Var}(X) = \\text{E}[X^{2}] - \\left(\\text{E}[X]\\right)^{2}\\]"
  },
  {
    "objectID": "posts/07_-_Expectation/Math_32_07_Expectation.html#example-boxing-bets",
    "href": "posts/07_-_Expectation/Math_32_07_Expectation.html#example-boxing-bets",
    "title": "07: Expectation",
    "section": "Example: Boxing Bets",
    "text": "Example: Boxing Bets\n\n\nBefore watching a boxing match, my friends and I made bets over which round the fight would end. A boxing match lasts up to 12 rounds. Each gambler pays $5 and is assigned a round randomly. The winner garners the whole pot of money. What is the expected value of the bet? What is the variance of the bet?"
  },
  {
    "objectID": "posts/07_-_Expectation/Math_32_07_Expectation.html#looking-ahead",
    "href": "posts/07_-_Expectation/Math_32_07_Expectation.html#looking-ahead",
    "title": "07: Expectation",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 16:\n\nWHW3\nLHW3\nDemographics Part 1 (survey)\n\nBe mindful of before-lecture quizzes\nExam 1 will be on Tues., Sept. 27\n\nmore information in weekly announcements\n\n\n\n\nsource"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#bernoulli-trials",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#bernoulli-trials",
    "title": "08: Binomial Distribution",
    "section": "Bernoulli Trials",
    "text": "Bernoulli Trials\nTo continue our exploration of discrete distributions, we will look at situations that have two disjoint possibilities.\n\n\n\n\n\n\nBernoulli Trials\n\n\n\nFor math symbols to represent a Bernoulli trial, the events \\(\\{1, 0\\}\\) have respective probabilities \\(p\\) and \\(1-p\\).\n\n\nFor example, for one flip of a coin\n\\[P(\\text{heads}) = p, \\quad P(\\text{tails}) = 1-p\\]\n\n\n\none coin, but not necessarily fair"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#arrangements",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#arrangements",
    "title": "08: Binomial Distribution",
    "section": "Arrangements",
    "text": "Arrangements\n\n\n\n\n\n\nPermutations\n\n\n\nPermutations (and the number of permutations) are the arrangements when order matters\n\n\n\n\n\n\n\n\nCombinations\n\n\n\nCombinations (and the number of combinations) are the arrangements when order does not matter\n\n\nFlipping 3 fair coins, what is the probability that heads will be observed exactly twice?"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#choose",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#choose",
    "title": "08: Binomial Distribution",
    "section": "Choose",
    "text": "Choose\n\n\n\\[\\binom{n}{k} = \\displaystyle\\frac{n!}{k!(n-k)!}\\]\n\nsaid ``n choose k’’\nThis choose operator keeps track of the number of permutations in a certain combination\nnote \\(0! = 1\\) (to avoid dividing by zero)\n\n\n\n\n\nfrom The Simpsons"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#binomial-distribution",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#binomial-distribution",
    "title": "08: Binomial Distribution",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\n\n\n\n\n\nBinomial Distribution\n\n\n\n\\[P(x = k) = \\binom{n}{k} p^{k}(1-p)^{n-k}\\]\n\n\\(0 \\leq k \\leq n\\), where \\(n\\) and \\(k\\) are whole numbers\n\\(0 \\leq p \\leq 1\\)"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#example-squirtle",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#example-squirtle",
    "title": "08: Binomial Distribution",
    "section": "Example: Squirtle",
    "text": "Example: Squirtle\n\n\n\n\n\n\n\n\nBinomial Distribution\n\n\n\n\\[P(x = k) = \\binom{n}{k} p^{k}(1-p)^{n-k}\\]\n\n\\(0 \\leq k \\leq n\\), where \\(n\\) and \\(k\\) are whole numbers\n\\(0 \\leq p \\leq 1\\)\n\n\n\n\nHistorically, Squirtle defeats Charizard 32% of the time. If there are 5 battles, what is the probability that Squirtle wins exactly 2 times?"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#example-charizard",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#example-charizard",
    "title": "08: Binomial Distribution",
    "section": "Example: Charizard",
    "text": "Example: Charizard\n\n\n\n\n\nCharizard\n\n\n\nHistorically, Charizard defeats Squirtle 68% of the time. If there are 5 battles, what is the probability that Charizard wins exactly 3 times?"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#symmetry",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#symmetry",
    "title": "08: Binomial Distribution",
    "section": "Symmetry",
    "text": "Symmetry\n\nPropertySquirtleCharizardR code\n\n\nThe previous two examples had the same answer, which is true due to a symmetry property in the choose operator:\n\\[\\binom{n}{k} = \\binom{n}{n-k}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nk <- 0:5\npk <- dbinom(k, 5, 0.32)\nk_bool <- k == 2\ndf <- data.frame(k, pk, k_bool)\n\ndf |>\n  ggplot(aes(x = k, y = pk, \n             color = k_bool, fill = k_bool)) +\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(x = k, y = pk, \n                 label = round(pk, 4)),\n             color = \"black\", fill = \"white\") +\n  labs(title = \"2 Squirtle Wins\",\n       subtitle = \"n = 5, k = 2, p = 0.32, P(k = 2) = 0.3220\",\n       caption = \"Math 32\",\n       x = \"wins\",\n       y = \"probability\") +\n  scale_color_manual(values = c(\"black\", \"#ca7721\")) +\n  scale_fill_manual(values = c(\"gray70\", \"#297383\")) +\n  theme(\n    legend.position = \"none\",\n    panel.background = element_blank()\n  )\n\n\n\n# plotly::ggplotly(ex2_plot)\n\n\nk <- 0:5\npk <- dbinom(k, 5, 0.68)\nk_bool <- k == 3\ndf <- data.frame(k, pk, k_bool)\n\ndf |>\n  ggplot(aes(x = k, y = pk, \n             color = k_bool, fill = k_bool)) +\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(x = k, y = pk, \n                 label = round(pk, 4)),\n             color = \"black\", fill = \"white\") +\n  labs(title = \"3 Charizard Wins\",\n       subtitle = \"n = 5, k = 3, p = 0.68, P(k = 3) = 0.3220\",\n       caption = \"Math 32\",\n       x = \"wins\",\n       y = \"probability\") +\n  scale_color_manual(values = c(\"black\", \"#de5138\")) +\n  scale_fill_manual(values = c(\"gray70\", \"#e53800\")) +\n  theme(\n    legend.position = \"none\",\n    panel.background = element_blank()\n  )\n\n\n\n# plotly::ggplotly(ex2_plot)\n\n\n\n\n\n\n\n\n\n\nHow do we pick between \\(p\\) and \\(1-p\\)?\n\n\n\nAt first, it does not matter how you define the binomial setting for what corresponds to \\(p\\) and what corresponds to \\(1-p\\), but you need to be consistent in the rest of the task for how you defined your variables and use the value(s) for \\(k\\)."
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#parameters",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#parameters",
    "title": "08: Binomial Distribution",
    "section": "Parameters",
    "text": "Parameters\nThe notation \\(X \\sim Ber(p)\\) is read as “random variable \\(X\\) has a Bernoulli distribution with parameter \\(p\\)”. Compute the expected value and variance for a Bernoulli trial."
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#parameters-1",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#parameters-1",
    "title": "08: Binomial Distribution",
    "section": "Parameters",
    "text": "Parameters\nThe notation \\(X \\sim Bin(n,p)\\) is read as ``random variable \\(X\\) has a binomial distribution with parameters \\(n\\) and \\(p\\)’’. Compute the expected value and variance for a binomial distribution.\nWe are assuming that the \\(n\\) trials are from each other, where independence in probability means that\n\\[P\\left(  \\{X_{i}\\}_{i=1}^{n} \\right) = \\displaystyle\\prod_{i=1}^{n} P(X_{i})\\]\nIn other words, we are sampling the Bernoulli trial \\(n\\) times with replacement, so we can simply multiply the results from the previous example by \\(n\\).\n\\[\\begin{array}{|c|c|c|}\n\\hline\n\\textbf{mean}               & \\mu & np \\\\ \\hline\n\\textbf{variance}           & \\sigma^{2} & np(1-p) \\\\ \\hline\n\\textbf{standard deviation} & \\sigma & \\sqrt{np(1-p)} \\\\ \\hline\n\\end{array}\\]"
  },
  {
    "objectID": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#looking-ahead",
    "href": "posts/08_-_Binomial Distribution/Math_32_08_Binomial_Distribution.html#looking-ahead",
    "title": "08: Binomial Distribution",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 23:\n\nWHW4\nLHW4\nDemographics Part 2 (survey)\n\nExam 1 will be on Tues., Sept. 27\n\nmore information in weekly announcements\n\n\n\n\nsource"
  },
  {
    "objectID": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#probability-mass-function",
    "href": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#probability-mass-function",
    "title": "9: Cumulative Computation",
    "section": "Probability Mass Function",
    "text": "Probability Mass Function\nLast time, we developed the probability mass function for the binomial distribution. The probability of choosing \\(k\\) observations among a sample size of \\(n\\), each observation with prior probability \\(p\\), is given by\n\\[P(k) = \\binom{n}{k}p^{k}(1-p)^{n-k}\\]\nNote the usual properties of probability:\n\neach probability is between zero and one (inclusively)\n\n\\[0 \\leq P(k) \\leq 1 \\quad\\text{for each } k\\]\n\nall probabilities add up to 100%\n\n\\[1 = \\displaystyle\\sum_{k = 0}^{n} \\binom{n}{k}p^{k}(1-p)^{n-k}\\]"
  },
  {
    "objectID": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#from-one-to-many",
    "href": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#from-one-to-many",
    "title": "9: Cumulative Computation",
    "section": "From One to Many",
    "text": "From One to Many\n\nExactlyAt MostExactlyMore Than\n\n\nThere are 4 parking spaces in front of the boba place. Suppose that each parking space tends to be occupied about 57 percent of the time. What is the probability that exactly 3 of the parking spaces are open?\n\n\n\nboba!\n\n\n\n\nThere are 4 parking spaces in front of the boba place. Suppose that each parking space tends to be occupied about 57 percent of the time. What is the probability that at most 2 of the parking spaces are open?\n\n\n\nboba!\n\n\n\n\nThere are 32 parking spaces in a row in a UC Merced parking lot. Suppose that each parking space tends to be occupied about 81 percent of the time. What is the probability that exactly 4 of the parking spaces are open?\n\n\n\nparking\n\n\n\n\nThere are 32 parking spaces in a row in a UC Merced parking lot. Suppose that each parking space tends to be occupied about 81 percent of the time. What is the probability that more than 5 of the parking spaces are open?\n\n\n\nparking"
  },
  {
    "objectID": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#leveraging-complements",
    "href": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#leveraging-complements",
    "title": "9: Cumulative Computation",
    "section": "Leveraging Complements",
    "text": "Leveraging Complements\nThere are 32 parking spaces in a row in a UC Merced parking lot. Suppose that each parking space tends to be occupied about 97 percent of the time. What is the probability that at least one of the parking spaces is open?\n\n\n\nparking"
  },
  {
    "objectID": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#looking-ahead",
    "href": "posts/09_-_Cumulative Calculations/Math_32_09_Cumulative_Computation.html#looking-ahead",
    "title": "9: Cumulative Computation",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Sept. 23:\n\nWHW4\nLHW4\nDemographics Part 2 (survey)\n\nExam 1 will be on Tues., Sept. 27\n\nmore information in weekly announcements\n\n\n\n\n\n\nsome found sign in Sausalito"
  },
  {
    "objectID": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#infinite-support",
    "href": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#infinite-support",
    "title": "10: Geometric Distribution",
    "section": "Infinite Support",
    "text": "Infinite Support\n\n\nHere let us assume an endless box of chocolates with random selection with replacement of\nWrite out some of the sample space. Let \\(F\\) be the event of choosing a favorite chocolate, so \\(F^{c}\\) is the event of choosing an average chocolate, \\(P(F) = p\\) and \\(P(F^{c}) = 1-p\\). Let \\(k\\) be the amount of chocolates chosen reaching a favorite chocolate\n\n\n\n\nForest Gump"
  },
  {
    "objectID": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#probability-mass-function",
    "href": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#probability-mass-function",
    "title": "10: Geometric Distribution",
    "section": "Probability Mass Function",
    "text": "Probability Mass Function\n\n\n\n\n\n\nGeometric Distribution Probability Mass Function\n\n\n\nA geometric distribution is a discrete probability distribution with\n\nprobability \\(p\\) for “success”\nprobability \\(1-p\\) for “failure”\nfor \\(k = 0, 1, 2, 3, ...\\)\n“success” on \\((k+1)^{\\text{th}}\\) trial\n\nThe probability mass function (PMF) is\n\\[f(X = k) = (1-p)^{k}p\\]\nThe cumulative mass function (CMF) is\n\\[F(X \\leq k) = 1 - (1-p)^{k+1}\\]"
  },
  {
    "objectID": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#cumulative-calculations",
    "href": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#cumulative-calculations",
    "title": "10: Geometric Distribution",
    "section": "Cumulative Calculations",
    "text": "Cumulative Calculations\n\n\n\n\n\nTed Mosby\n\n\n\nTed Mosby is setting up his weekend plans. Barney convinced him to try out an app called Tinder. “Ted Mosby, Architect” has a 2/3 chance of setting up a date among those he “swipes right”. Suppose that Ted stops using Tinder this session once he sets up a date.\n\nCompute the probability that Ted needs exactly 4 ``swipes right’’ to set up a date.\nCompute the probability that Ted needs at most 4 ``swipes right’’ to set up a date."
  },
  {
    "objectID": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#complementary-cumulative-mass-function",
    "href": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#complementary-cumulative-mass-function",
    "title": "10: Geometric Distribution",
    "section": "Complementary Cumulative Mass Function",
    "text": "Complementary Cumulative Mass Function\n\n\n\n\n\n\nComplementary Cumulative Mass Function\n\n\n\nWhen modeling with a geometric distribution—i.e. \\(X \\sim Geo(p)\\)—the probability that “success” takes more than \\(k\\) trials is\n\\[P(X > k) = (1-p)^{k+1}\\]\n\n\n\nMore ThanConditional ProbabilityConditional Probability 2\n\n\n\n\n\n\n\nRebecca Bunch\n\n\n\nRebecca Bunch follows Josh Chan, whom she briefly dated as a teenager, by moving to West Covina, California. Suppose that it may take a while for Rebecca and Josh to reunite and there is a 29 percent chance of them meeting during any particular week. What is the probability that it will take Rebecca more than 3 weeks to reunite with Josh?\n\n\n\n\n\n\n\n\n\nRebecca Bunch\n\n\n\nWhat is the probability that it will take Rebecca more than 9 weeks to reunite with Josh given that she has already spent more than 5 weeks in West Covina?\n\n\n\n\n\n\n\n\n\nRebecca Bunch\n\n\n\nStill holding on to that 29 percent chance of reuniting with Josh, compute the probability that it will take Rebecca more than 36 weeks to reunite with Josh given that she has already spent more than 32 weeks in West Covina."
  },
  {
    "objectID": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#memoryless-property",
    "href": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#memoryless-property",
    "title": "10: Geometric Distribution",
    "section": "Memoryless Property",
    "text": "Memoryless Property\nThe previous two examples demonstrated the memoryless property.\n\n\n\n\n\n\nMemoryless Property\n\n\n\nThe geometric distribution is the only discrete probability distribution that has the memoryless property:\n\\[P(X \\geq a + b | X \\geq b) = P(X \\geq a)\\]"
  },
  {
    "objectID": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#looking-ahead",
    "href": "posts/10_-_Geometric Distribution/Math_32_10_Geometric_Distribution.html#looking-ahead",
    "title": "10: Geometric Distribution",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Oct. 7:\n\nWHW5\nLHW5\nMid-Semester Survey\n\nExam 1 will be on Tues., Nov. 1"
  },
  {
    "objectID": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#continuous-variables",
    "href": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#continuous-variables",
    "title": "11: Continuous Distributions",
    "section": "Continuous Variables",
    "text": "Continuous Variables\n\n\n\nImage Credit: G2 Learing Hub\n\n\n\nA discrete variable is “countable” (has values that can be in a list)\nA continuous variable has values that cannot be written as a list (“uncountable”)"
  },
  {
    "objectID": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#uniform-distribution",
    "href": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#uniform-distribution",
    "title": "11: Continuous Distributions",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nYou arrive at a bus stop at 10 o’clock, knowing that the bus will arrive at some time uniformly distributed between 10:00 and 10:30.\n\nNormalizationFewerMoreConditional\n\n\n\n\nWe build a probability density function (PDF) by ensuring that the area under the curve equals 100 percent (i.e. one square unit).\n\n\n\n\n\n\n\n\nWhat is the probability that you will have to wait fewer than 12 minutes?\n\n\n\n\n\n\n\n\nWhat is the probability that you will have to wait longer than 10 minutes?\n\n\n\n\n\n\n\n\nIf at 10:15 the bus has not yet arrived, what is the probability that you will have to wait at least an additional 10 minutes?"
  },
  {
    "objectID": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#linear-distribution",
    "href": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#linear-distribution",
    "title": "11: Continuous Distributions",
    "section": "Linear Distribution",
    "text": "Linear Distribution\n\nYou arrive at a bus stop at 10 o’clock, knowing that the bus will arrive at some time linearly distributed between 10:00 and 10:30. The probability density function (PDF) is\n\\[f(x) = \\begin{cases} -\\displaystyle\\frac{1}{450}x + \\displaystyle\\frac{1}{15} & 0 \\leq x \\leq 30 \\\\ 0 & \\text{otherwise} \\end{cases}\\]\n\nPDFFewerFewerBetween\n\n\n\n\nProbability Density Function (PDF)\n\n\n\n\n\n\n\n\nWhat is the probability that you will have to wait fewer than 7 minutes?\n\n\n\n\n\n\n\n\nWhat is the probability that you will have to wait fewer than 11 minutes?\n\n\n\n\n\n\n\n\nWhat is the probability that you will have to wait between 7 and 11 minutes?"
  },
  {
    "objectID": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#cumulative-density-function",
    "href": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#cumulative-density-function",
    "title": "11: Continuous Distributions",
    "section": "Cumulative Density Function",
    "text": "Cumulative Density Function\n\nThere are no nonzero probabilities to the left. The CDF “starts with zero” probability. Here, \\(F(0) = 0\\)\nSince all probabilities add up to 100%, the CDF ends at one”. Here, \\(F(30) = 1\\)\n\n\n\n\nCDF"
  },
  {
    "objectID": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#looking-ahead",
    "href": "posts/11_-_Continuous Distributions/Math_32_11_Geometric_Distribution.html#looking-ahead",
    "title": "11: Continuous Distributions",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\ndue Fri., Oct. 7:\n\nWHW5\nLHW5\nMid-Semester Survey\n\nExam 2 will be on Tues., Nov. 1"
  }
]