{
  "hash": "0b86dc045e9100b0d08597956b74d881",
  "result": {
    "markdown": "---\ntitle: \"Confidence Intervals\"\nauthor: \"Derek Sollberger\"\ndate: \"2023-04-21\"\n# format: \n#   revealjs:\n#     scrollable: true\nformat: html\n# server: shiny\n---\n\n\n\\newcommand{\\ds}{\\displaystyle}\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## 31: Confidence Intervals (Concept)\n\n* Source:  **Statistical Inference via Data Science:** *A Modern Dive into R and the Tidyverse*\n* Chapter 8: Bootstrapping and Confidence Intervals\n* [https://moderndive.com/8-confidence-intervals.html](https://moderndive.com/8-confidence-intervals.html)\n\n## Setting: Pennies\n\nAmong pennies in circulation in 2019, what was the average year of minting?  We have a sample size of 50 pennies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# looking at the data set\npennies_sample\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 2\n      ID  year\n   <int> <dbl>\n 1     1  2002\n 2     2  1986\n 3     3  2017\n 4     4  1988\n 5     5  2008\n 6     6  1983\n 7     7  2008\n 8     8  1996\n 9     9  2004\n10    10  2000\n# ℹ 40 more rows\n```\n:::\n:::\n\n\n## Sample Distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# visualizing the the pennies\npennies_sample %>%\n  ggplot(aes(x = year)) +\n  geom_dotplot(binwidth = 1, color = \"tan3\", fill = \"tan4\") +\n  labs(title = \"Pennies Sample\",\n       subtitle = \"observed in 2019\",\n       caption = \"Source: Modern Dive\",\n       x = \"year\",\n       y = \"proportion\")\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# visualizing the distribution of the pennies\np1 <- pennies_sample %>%\n  ggplot(aes(x = year)) +\n  geom_histogram(binwidth = 10, color = \"tan3\", fill = \"tan4\") +\n  labs(title = \"Pennies Sample\",\n       subtitle = \"observed in 2019\",\n       caption = \"Source: Modern Dive\")\n\n# display graph (in addition to storing the graph in a variable)\np1\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# sample mean\npennies_sample %>% summarize(xbar = mean(year))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n   xbar\n  <dbl>\n1 1995.\n```\n:::\n:::\n\n\n\n## Resampling\n\nUsing the available sample of data to fabricate another sample is called *resampling*.\n\n## Resampling Once\n\nSuppose that we took the 50 pennies and resampled once while sampling *with replacement*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_resampled_once <- pennies_sample %>%\n  sample_n(size = 50, replace = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# visualizing the distribution of the pennies\np2 <- pennies_resampled_once %>%\n  ggplot(aes(x = year)) +\n  geom_histogram(binwidth = 10, color = \"tan3\", fill = \"tan4\") +\n  labs(title = \"Pennies Resampled Once\",\n       subtitle = \"sampled with replacement\",\n       caption = \"Source: Modern Dive\")\n\n# (using `patchwork` package to arrange plots side-by-side\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# a different sample mean\npennies_resampled_once %>% summarize(xbar = mean(year))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n   xbar\n  <dbl>\n1 1995.\n```\n:::\n:::\n\n\n\n## Resampled Many Times\n\nSuppose now that we have each person in a 30-student discussion section repeat the act of drawing those 50 pennies with replacement.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_resampled_many <- pennies_sample %>%\n  rep_sample_n(size = 50, replace = TRUE, reps = 30)\n```\n:::\n\n\nNow we have each virtual student report their mean year.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_resampled_many %>%\n  group_by(replicate) %>%\n  summarize(mean_year = mean(year))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 × 2\n   replicate mean_year\n       <int>     <dbl>\n 1         1     1998.\n 2         2     1991.\n 3         3     1996.\n 4         4     1991.\n 5         5     1998.\n 6         6     1995.\n 7         7     1993.\n 8         8     1994.\n 9         9     1997.\n10        10     1995.\n# ℹ 20 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(pennies_sample$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1962    1983    1996    1995    2008    2018 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_resampled_many %>%\n  group_by(replicate) %>%\n  mutate(mean_year = mean(year)) %>%\n  ungroup() %>%\n  select(replicate, mean_year) %>%\n  distinct() %>%\n  ggplot(aes(x = mean_year)) +\n  geom_histogram(binwidth = 1, color = \"tan3\", fill = \"tan4\") +\n  labs(title = \"Resampling Results\",\n       subtitle = \"N = 30 resamples\",\n       caption = \"Source: Modern Dive\")\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nOut of curiosity, let us push this process to $N = 1337$ resamples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_resampled_means <- pennies_sample %>%\n  rep_sample_n(size = 50, replace = TRUE, reps = 1337) %>%\n  group_by(replicate) %>%\n  mutate(mean_year = mean(year)) %>%\n  ungroup() %>%\n  select(replicate, mean_year) %>%\n  distinct() \n\npennies_resampled_means %>%\n  ggplot(aes(x = mean_year)) +\n  geom_histogram(binwidth = 1, color = \"tan3\", fill = \"tan4\") +\n  labs(title = \"Resampling Results\",\n       subtitle = \"N = 1337 resamples\",\n       caption = \"Source: Modern Dive\")\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n# Confidence Intervals\n\n## Toward Confidence Intervals\n\nThe standard deviation of a sampling distribution is called the *standard error*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxbar <- mean(pennies_resampled_means$mean_year)\nSE   <- sd(pennies_resampled_means$mean_year)\n```\n:::\n\n\nWe can build a 95% confidence interval by computing $\\bar{x} \\pm 1.96*SE$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(xbar - 1.96*SE, xbar + 1.96*SE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1991.377 1999.624\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_resampled_means %>%\n  ggplot(aes(x = mean_year)) +\n  geom_histogram(binwidth = 1, color = \"tan3\", fill = \"tan4\") +\n  geom_vline(xintercept = c(xbar - 1.96*SE, xbar + 1.96*SE), color = \"yellow\", linewidth = 2) +\n  labs(title = \"Resampling Results\",\n       subtitle = \"N = 1337 resamples\",\n       caption = \"Source: Modern Dive\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n## Using the infer package\n\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_sample %>%\n  specify(response = year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: year (numeric)\n# A tibble: 50 × 1\n    year\n   <dbl>\n 1  2002\n 2  1986\n 3  2017\n 4  1988\n 5  2008\n 6  1983\n 7  2008\n 8  1996\n 9  2004\n10  2000\n# ℹ 40 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_sample %>%\n  specify(response = year) %>%\n  calculate(stat = \"mean\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: year (numeric)\n# A tibble: 1 × 1\n   stat\n  <dbl>\n1 1995.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npennies_sample %>%\n  specify(response = year) %>%\n  generate(reps = 1337, type = \"bootstrap\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: year (numeric)\n# A tibble: 66,850 × 2\n# Groups:   replicate [1,337]\n   replicate  year\n       <int> <dbl>\n 1         1  1983\n 2         1  1992\n 3         1  2015\n 4         1  2018\n 5         1  1997\n 6         1  1988\n 7         1  2017\n 8         1  1976\n 9         1  1985\n10         1  2015\n# ℹ 66,840 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution <- pennies_sample %>%\n  specify(response = year) %>%\n  generate(reps = 1337, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\n\n# print\nbootstrap_distribution\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: year (numeric)\n# A tibble: 1,337 × 2\n   replicate  stat\n       <int> <dbl>\n 1         1 1998.\n 2         2 1994.\n 3         3 1990.\n 4         4 1998.\n 5         5 1996.\n 6         6 1996.\n 7         7 1998.\n 8         8 1996.\n 9         9 1998.\n10        10 1993.\n# ℹ 1,327 more rows\n```\n:::\n:::\n\n\n## Bootstrap Distribution\n\nThe resulting distribution from sampling without replacement is called a **bootstrap distribution**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisualise(bootstrap_distribution)\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## Infer get_ci()\n\nThere are also wrappers in the `infer` package to extract the confidence interval\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution %>%\n  get_confidence_interval(point_estimate = mean(bootstrap_distribution$stat), \n                          level = 0.95, type = \"se\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1    1991.    2000.\n```\n:::\n:::\n\n\nAlternatively, we can use percentiles to build our confidence intervals.  This is useful when the data is not normally distributed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution %>%\n  get_confidence_interval(level = 0.95, type = \"percentile\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1    1991.    1999.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nSE_CI <- bootstrap_distribution %>%\n  get_ci(point_estimate = mean(bootstrap_distribution$stat),\n         level = 0.95, type = \"se\")\n\nvisualize(bootstrap_distribution) +\n  shade_ci(endpoints = SE_CI, color = \"#DAA900\", fill = \"#002856\")\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Inference\n\nHow do we describe confidence intervals?\n\n## Example: Bowl of Marbles\n\nThe `bowl` data was literally a classroom bowl of red and white marbles\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbowl %>%\n  ggplot(aes(x = color, fill = color)) +\n  geom_bar(stat = \"count\", color = \"black\") +\n  scale_fill_manual(values = c(\"red\", \"white\")) +\n  labs(title = \"Bowl of Marbles\",\n       subtitle = \"population is known\",\n       caption = \"Source: Modern Dive\")\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nwhere we know the true proportion of red marbles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbowl %>%\n  summarize(proportion_red = mean(color == \"red\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  proportion_red\n           <dbl>\n1          0.375\n```\n:::\n:::\n\n\n## Simulations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCI_simulation <- function(confidence = 95, sample_size = 25, num_intervals = 10){\n  # Constants\n  alpha <- 1 - confidence/100\n  n <- sample_size\n  N <- num_intervals\n  proportion_red <- 0.375 #true population proportion\n  \n  # vector allocation\n  left <- rep(NA, N)\n  right <- rep(NA, N)\n  captured <- rep(NA, N)\n  \n  for(i in 1:N){\n    this_sample <- sample(bowl$color, n, replace = TRUE)\n    phat <- mean(this_sample == \"red\") #sample proportion\n    \n    #margin of error\n    E <- qnorm(1 - alpha/2)*sqrt( phat*(1-phat)/n)\n    \n    #this confidence interval\n    left[i] <- phat - E\n    right[i] <- phat + E\n    \n    #did the confidence interval capture the true proportion?\n    captured[i] <- ifelse(left[i] <= proportion_red & right[i] >= proportion_red, TRUE, FALSE)\n  }\n  \n  # graph\n  df <- data.frame(left, right, captured)\n  ggplot(df, aes(x = left, y = 1:N)) +\n    geom_vline(xintercept = proportion_red, color = \"black\") +\n    geom_segment(aes(x = left, y = 1:N, \n                     xend = right, yend = 1:N,\n                     color = captured)) +\n    labs(title = \"Simulation of bowl samples\",\n         subtitle = paste0(\"alpha = \", alpha, \", n = \", n),\n         caption = \"Bio 175\", \n         x = \"proportion red\",\n         y = \"iteration\") +\n    theme_minimal()\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nCI_simulation(confidence = 95, sample_size = 25, num_intervals = 100)\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n::::: {.panel-tabset}\n\n## Significance Levels\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- CI_simulation(80, 25, 100) + theme(legend.position = \"none\")\np2 <- CI_simulation(95, 25, 100) + theme(legend.position = \"none\")\np3 <- CI_simulation(99, 25, 100) + theme(legend.position = \"none\")\n\np1 + p2 + p3\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nAs we request more confidence, the confidence intervals are more likely to include the true population parameter.\n\n## Sample Sizes\n\n\n::: {.cell}\n\n```{.r .cell-code}\np4 <- CI_simulation(95, 25, 100) + theme(legend.position = \"none\")\np5 <- CI_simulation(95, 100, 100) + theme(legend.position = \"none\")\np6 <- CI_simulation(95, 400, 100) + theme(legend.position = \"none\")\n\np4 + p5 + p6\n```\n\n::: {.cell-output-display}\n![](Math_32_-_31_-_Confidence_Intervals_concept_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nAs we use larger sample sizes, the confidence intervals are more likely to include the true population parameter.\n\n:::::\n\n\n\n\n\n## Looking Ahead\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n- WHW10 (due today)\n\n- WHW11\n- LHW9\n- LHW10\n  \nFinal Exam will be on May 6\n\n- more information in weekly announcement\n:::\n\n::: {.column width=\"40%\"}\n![](global_min.png)\n\n[tweet source](https://mobile.twitter.com/ChelseaParlett/status/1648898736784039936)\n:::\n\n::::\n\n\n\n\n\n\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::\n\n",
    "supporting": [
      "Math_32_-_31_-_Confidence_Intervals_concept_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}