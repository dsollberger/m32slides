{
  "hash": "19ed0c9d0d3dd40687a039e2447749ac",
  "result": {
    "markdown": "---\ntitle: \"20: Law of Large Numbers\"\nauthor: \"Derek Sollberger\"\ndate: \"2022-11-08\"\n# format: \n#   revealjs:\n#     scrollable: true\nformat: html\n# server: shiny\n---\n\n\n\\newcommand{\\ds}{\\displaystyle}\n\n\n::: {.cell}\n\n:::\n\n\n\n## Today: Law of Large Numbers\n\n**Goal**: start to understand error as it relates to sample size\n\n**Objectives**:\n\n* Distribution of the mean $\\bar{X}_{n}$\n* Chebyshev's Inequality\n* Law of Large Numbers\n\n\n## i.i.d.\n\n:::{.callout-tip}\n## i.i.d.\n\nLet $X_{1}, X_{2}, X_{3}, ...$ be an *independent and identically distributed* sequence of random variables (denoted ``i.i.d'')\n\n- each $X_{i}$ is independent of each other\n- each $X_{i}$ has mean $\\mu$\n- each $X_{i}$ has variance $\\sigma^{2}$\n:::\n\nLet us now seek the distribution of the mean\n\n$$\\bar{X}_{n} = \\ds\\frac{X_{1} + X_{2} + ... + X_{n}}{n}$$\n\n\n- expected value\n- variance\n\n\n## Distribution of Mean\n\n:::{.callout-note}\n## Distribution of Mean\n\nIf $\\bar{X}_{n}$ is the mean of $n$ independent and identical random variables, each with mean $\\mu$ and variance $\\sigma^{2}$, then we can describe the distribution of $\\bar{X}_{n}$ with\n\n\n$$\\text{E}[\\bar{X}_{n}] = \\mu \\quad\\text{and}\\quad \\text{Var}(\\bar{X}_{n}) = \\ds\\frac{\\sigma^{2}}{n}$$\n\n:::\n\n\n## Far from the Mean\n\n:::{.callout-tip}\n## Far from the Mean\n\nIdea: we can get a sense of the probability that, for a particular boundary location $a$, an observation lies outside of the interval\n\n$$(\\mu - a, \\mu + a)$$\n\n:::\n\n- $\\mu$: population average\n- $a$: tolerance\n\n**Claim**: $P(|X - \\mu| \\geq a) \\leq \\ds\\frac{\\text{Var}(X)}{a^{2}}$\n\n\n## Chebyshev's Inequality\n\n:::{.callout-note}\n## Chebyshev's Inequality\n\nFor a random variable $X$ and boundary location $a$,\n\n$$P(|X - \\mu| \\geq a) \\leq \\ds\\frac{\\text{Var}(X)}{a^{2}}$$\n\n:::\n\nThat is, if we know the variance of a distribution, we can compute an upper bound for the probability of rare events!\n\n\n## Law of Large Numbers\n\nThe Law of Large Numbers basically combines Chebyshev's Inequality with the earlier work for the distribution of the mean:\n\n- $\\text{E}[\\bar{X}_{n}] = \\mu \\quad\\text{and}\\quad \\text{Var}(\\bar{X}_{n}) = \\ds\\frac{\\sigma^{2}}{n}$\n- $P(|X - \\mu| \\geq a) \\leq \\ds\\frac{\\text{Var}(X)}{a^{2}}$\n\nIdea:  What happens when we observe a lot of data?\n\n:::{.callout-note}\n## Law of Large Numbers\n\nTaking the limit as $n$ goes to infinity, we arrive at the *Law of Large Numbers*:\n\n\n$$\\ds\\lim_{n \\to \\infty} P(|\\bar{X}_{n} - \\mu| \\geq a) \\leq \\ds\\lim_{n \\to \\infty} \\ds\\frac{\\sigma^{2}}{a^{2} n} = 0$$\n\n:::\n\nThat is, the probability that the mean of a sample of random variables is ``far'' from the inherent expected value eventually goes to zero.\n\n\n## Nerdy Example\n\nHow many numbers between zero and one do we have to add up to have a sum that is greater than one?\n\n- Let $X_{i} \\sim U(0,1)$ be i.i.d.\n- Let $Y$ be the amount of $X_{i}$ added together to get a sum greater than one\n- For a conservative estimate, suppose $Y \\sim U(2,6)$, then \n    \n\n$$\\text{Var}(Y) = \\ds\\frac{4}{3}$$\n\n- Empirically (i.e. computer simulation), we saw convergence toward \n    \n\n$$\\bar{Y}_{n} = e \\approx 2.7183$$\n\n\nHow many trials are needed so that the simulations converge to a mean within 0.01 of the true answer with at least 95 percent probability?\n\n\n## Looking Ahead\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n- WHW9\n  \nFinal Exam will be on Dec. 8\n\n:::\n\n::: {.column width=\"50%\"}\n![](orange.png)\n\n[tweet source](https://mobile.twitter.com/mathladyhazel/status/1589448459131637760)\n\n:::\n\n::::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::\n",
    "supporting": [
      "Math_32_20_Law_of_Large_Numbers_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}