{
  "hash": "f9924ef1c8bf77ad5c36063acf05d9dd",
  "result": {
    "markdown": "---\ntitle: \"30: Regression Analysis\"\nauthor: \"Derek Sollberger\"\ndate: \"2023-04-19\"\n# format: \n#   revealjs:\n#     scrollable: true\nformat: html\n# server: shiny\n---\n\n\n\\newcommand{\\ds}{\\displaystyle}\n\n\n::: {.cell}\n\n:::\n\n\n\n## 30: Regression Analysis\n\n**Goal**: Discuss the validity of regression models\n\n**Objectives**:\n\n- explore nonlinear regression models\n- practice using the coefficient of determination\n\n\n## Setting\n\n**Kaggle** was founded in April 2010 and is a data science resource that hosts many public data sets and hosts machine learning competitions.\n\n* predictor variable\n\n$$X: \\text{months since founding}$$\n\n* response variable\n\n$$Y: \\text{number of users (in millions)}$$\n\n\n## Data\n\nThis data set is relatively small, so we can quickly transcribe it into an R data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(\n  months = c(0,86, 101, 110, 118, 123, 129, 134, 139, 143, 147),\n  users = 0:10\n)\n```\n:::\n\n\nSource: https://www.kaggle.com/discussions/general/332147\n\n## Linear Model\n\n$$\\hat{y} = a + bx$$\n\n::: {.callout-warning collapse=\"true\"}\n## Dependent Variable\n\nIn model equations, the response variable is listed first\n\n$$\\sim \\quad \\text{:} \\quad \\text{explained by}$$\n\nthen the predictor variables.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_model <- lm(users ~ months, data = df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = users ~ months, data = df)\n\nCoefficients:\n(Intercept)       months  \n   -2.38965      0.06609  \n```\n:::\n:::\n\n\n\n## Prediction\n\nExample: As of this writing (April 2023), there have been 156 months since Kaggle was established.  Use a linear regression model to predict how many users are on Kaggle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(linear_model, newdata = data.frame(months = 156))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n7.919814 \n```\n:::\n:::\n\n\n\n## Data Visualization\n\nIn `ggplot2`, the `geom_smooth` layer can quickly graph the linear regression model.\n\n::::: {.panel-tabset}\n\n## Graph\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](Math_32_30_Regression_Analysis_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitle_string = \"<span style='color:#FF0000'>red: <b>regression model</b></span>, \n<span style='color:#0000FF'>blue: <b>true data</b></span>\"\n\ndf |>\n  ggplot(aes(x = months, y = users)) +\n  geom_point(color = \"blue\", size = 3) +\n  geom_smooth(color = \"red\", method = \"lm\", se = FALSE) +\n  labs(title = \"Kaggle Community\",\n       subtitle = subtitle_string,\n       caption = \"Math 32\",\n       x = \"months since April 2010 founding\",\n       y = \"number of users (in millions)\") +\n  theme_minimal() +\n  theme(plot.subtitle = element_markdown())\n```\n:::\n\n\n:::::\n\n\n## Quadratic Regression\n\n$$\\hat{y} = a + bx + cx^{2}$$\n\nBy default, `R` uses orthogonal polynomials in model creation.  If we would rather gather easy-to-interpret coefficients in the model form above, use `raw = TRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2_model <- lm(users ~ poly(months, 2, raw = TRUE), data = df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd2_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = users ~ poly(months, 2, raw = TRUE), data = df)\n\nCoefficients:\n                 (Intercept)  poly(months, 2, raw = TRUE)1  \n                     0.06293                      -0.08169  \npoly(months, 2, raw = TRUE)2  \n                     0.00100  \n```\n:::\n:::\n\n\nExample: As of this writing (April 2023), there have been 156 months since Kaggle was established.  Use a quadratic regression model to predict how many users are on Kaggle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(d2_model, newdata = data.frame(months = 156))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n11.66495 \n```\n:::\n:::\n\n\n\n## Data Visualization\n\nIn `ggplot2`, the `geom_smooth` layer can quickly graph the polynomial regression model.\n\n::::: {.panel-tabset}\n\n## Graph\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Math_32_30_Regression_Analysis_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitle_string = \"<span style='color:#FF0000'>red: <b>regression model</b></span>, \n<span style='color:#0000FF'>blue: <b>true data</b></span>, quadratic regression\"\n\ndf |>\n  ggplot(aes(x = months, y = users)) +\n  geom_point(color = \"blue\", size = 4) +\n  geom_smooth(color = \"red\", \n              formula = y ~ poly(x,2, raw = TRUE),\n              method = \"lm\", \n              se = FALSE) +\n  labs(title = \"Kaggle Community\",\n       subtitle = subtitle_string,\n       caption = \"Math 32\",\n       x = \"months since April 2010 founding\",\n       y = \"number of users (in millions)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\",\n                                  hjust = 0.5,\n                                  size = 20),\n        plot.subtitle = element_markdown(hjust = 0.5,\n                                         size = 15),\n        plot.caption = element_text(size = 10))\n```\n:::\n\n\n:::::\n\n\n## Cubic Regression\n\n$$\\hat{y} = a + bx + cx^{2} + dx^{3}$$\n\nBy default, `R` uses orthogonal polynomials in model creation.  If we would rather gather easy-to-interpret coefficients in the model form above, use `raw = TRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd3_model <- lm(users ~ poly(months, 3, raw = TRUE), data = df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd3_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = users ~ poly(months, 3, raw = TRUE), data = df)\n\nCoefficients:\n                 (Intercept)  poly(months, 3, raw = TRUE)1  \n                   1.360e-03                     1.485e-02  \npoly(months, 3, raw = TRUE)2  poly(months, 3, raw = TRUE)3  \n                  -6.207e-04                     6.691e-06  \n```\n:::\n:::\n\n\nExample: As of this writing (April 2023), there have been 156 months since Kaggle was established.  Use a cubic regression model to predict how many users are on Kaggle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(d3_model, newdata = data.frame(months = 156))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n12.61522 \n```\n:::\n:::\n\n\n## Data Visualization\n\nIn `ggplot2`, the `geom_smooth` layer can quickly graph the polynomial regression model.\n\n::::: {.panel-tabset}\n\n## Graph\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Math_32_30_Regression_Analysis_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitle_string = \"<span style='color:#FF0000'>red: <b>regression model</b></span>, \n<span style='color:#0000FF'>blue: <b>true data</b></span>, cubic regression\"\n\ndf |>\n  ggplot(aes(x = months, y = users)) +\n  geom_point(color = \"blue\", size = 5) +\n  geom_smooth(color = \"red\", \n              formula = y ~ poly(x,3, raw = TRUE),\n              method = \"lm\", \n              se = FALSE) +\n  labs(title = \"Kaggle Community\",\n       subtitle = subtitle_string,\n       caption = \"Math 32\",\n       x = \"months since April 2010 founding\",\n       y = \"number of users (in millions)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\",\n                                  hjust = 0.5,\n                                  size = 20),\n        plot.subtitle = element_markdown(hjust = 0.5,\n                                         size = 15),\n        plot.caption = element_text(size = 10))\n```\n:::\n\n\n:::::\n\n\n## Analysis of Variance\n\n- denote $y_{i}$ for true outcomes\n- denote $\\hat{y}_{i}$ for estimates (or predictions)\n- then $y_{i} - \\hat{y}_{i}$ is the $i^{\\text{th}}$ *residual*\n\n$$SS_{\\text{res}} = \\ds\\sum_{i=1}^{n}(y_{i} - \\hat{y_{i}})^{2}$$\n\n$$SS_{\\text{tot}} = \\ds\\sum_{i=1}^{n}(y_{i} - \\bar{y_{i}})^{2}$$\n\n\n## Variation\n\n$$R^{2} = 1 - \\ds\\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} = \\ds\\frac{\\text{explained variation}}{\\text{total variation}}$$\n\n* for linear regression, $R^{2}$ is the square of correlation\n* range of $R^{2}$ is $[0,1]$\n* higher $R^{2}$ implies better model\n\n\n## Adjusted Coefficient of Determination\n\nTo later mitigate issues such as the curse of dimensionality in more complex models, statisticians recommend use of an adjusted $R^{2}$ such as\n\n$$R^{2} = 1 - \\ds\\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} \\cdot \\ds\\frac{df_{\\text{tot}}}{df_{\\text{res}}}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(linear_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = users ~ months, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.2938 -1.6442 -0.1355  1.5715  2.6750 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -2.38965    1.78199  -1.341  0.21278   \nmonths       0.06609    0.01503   4.398  0.00172 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.97 on 9 degrees of freedom\nMultiple R-squared:  0.6825,\tAdjusted R-squared:  0.6472 \nF-statistic: 19.35 on 1 and 9 DF,  p-value: 0.001724\n```\n:::\n:::\n\n\n\n## Exponential Regression\n\n$$\\hat{y} = a*b^{x}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# shouldn't compute ln 0\ndf$users[1] <- 0.1\n\nexp_model <- lm(log(users) ~ months, data = df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# coefficients of ln a and ln b\nexp_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(users) ~ months, data = df)\n\nCoefficients:\n(Intercept)       months  \n   -2.44344      0.03226  \n```\n:::\n:::\n\n\nExample: As of this writing (April 2023), there have been 156 months since Kaggle was established.  Use an exponential regression model to predict how many users are on Kaggle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- exp(summary(exp_model)$coefficients[1])\nb <- exp(summary(exp_model)$coefficients[2])\na*b^{156}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 13.31783\n```\n:::\n:::\n\n\n## Data Visualization\n\nIn `ggplot2`, the `geom_function` layer can quickly graph a custom function.\n\n::::: {.panel-tabset}\n\n## Graph\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Math_32_30_Regression_Analysis_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitle_string = \"<span style='color:#FF0000'>red: <b>regression model</b></span>, \n<span style='color:#0000FF'>blue: <b>true data</b></span>, exponential regression\"\n\nf <- function(x) { a*b^x }\n\ndf |>\n  ggplot(aes(x = months, y = users)) +\n  geom_point(color = \"blue\", size = 5) +\n  geom_function(fun = f, color = \"red\", linewidth = 2) +\n  labs(title = \"Kaggle Community\",\n       subtitle = subtitle_string,\n       caption = \"Math 32\",\n       x = \"months since April 2010 founding\",\n       y = \"number of users (in millions)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\",\n                                  hjust = 0.5,\n                                  size = 20),\n        plot.subtitle = element_markdown(hjust = 0.5,\n                                         size = 15),\n        plot.caption = element_text(size = 10))\n```\n:::\n\n\n:::::\n\n\n## Model Selection\n\nLet us use the adjusted $R^{2}$ values to judge our models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(linear_model)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6472128\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(d2_model)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9923513\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(d3_model)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9994897\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(exp_model)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9899031\n```\n:::\n:::\n\n\n\n## What Happened\n\nOn April 17, 2023, Kaggle surpassed 13 million users!\n\n![source](kaggle_community_1.png)\n\n[tweet source](https://mobile.twitter.com/kaggle/status/1648009624191115282)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(d3_model, newdata = data.frame(months = 156))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n12.61522 \n```\n:::\n:::\n\n\n## Looking Ahead\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n- WHW10\n- LHW9\n  \nFinal Exam will be on May 6\n\n- more information in weekly announcement\n:::\n\n::: {.column width=\"50%\"}\n![Even Kaggle makes mistakes!](kaggle_community_2.png)\n\n[tweet source](https://mobile.twitter.com/kaggle/status/1648091344831692800)\n:::\n\n::::\n\n\n\n\n\n\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::\n",
    "supporting": [
      "Math_32_30_Regression_Analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}