{
  "hash": "d731b21d09dad612d409976547e7115b",
  "result": {
    "markdown": "---\ntitle: \"35: Introduction to Machine Learning (2)\"\nauthor: \"Derek Sollberger\"\ndate: \"2023-05-01\"\n# format: \n#   revealjs:\n#     scrollable: true\nformat: html\n# server: shiny\n---\n\n\n\\newcommand{\\ds}{\\displaystyle}\n\n\n## 35: Introduction to Machine Learning (2)\n\n**Goal**: overview of some machine learning techniques\n\n**Objectives**:\n\n- introduce random forests\n- introduce clustering\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(\"caret\")\nlibrary(\"ggraph\")\nlibrary(\"igraph\")\nlibrary(\"patchwork\")\nlibrary(\"randomForest\")\nlibrary(\"skimr\")          #tools to quickly extract summary statistics\nlibrary(\"tidymodels\")\nlibrary(\"tidyverse\")\n\nset.seed(123) #actually needed to turn off some randomization\n```\n:::\n\n\n## Data: Eggs\n\nSource: [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-04-11/readme.md) data set from April 11, 2023\n\nThe data this week comes from The Humane League's US Egg Production dataset by Samara Mendez. Dataset and code is available for this project on OSF at US Egg Production Data Set.  This dataset tracks the supply of cage-free eggs in the United States from December 2007 to February 2021.\n\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df_raw <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-04-11/egg-production.csv')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(egg_df_raw, give.attr = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspc_tbl_ [220 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ observed_month: Date[1:220], format: \"2016-07-31\" \"2016-08-31\" ...\n $ prod_type     : chr [1:220] \"hatching eggs\" \"hatching eggs\" \"hatching eggs\" \"hatching eggs\" ...\n $ prod_process  : chr [1:220] \"all\" \"all\" \"all\" \"all\" ...\n $ n_hens        : num [1:220] 57975000 57595000 57161000 56857000 57116000 ...\n $ n_eggs        : num [1:220] 1.15e+09 1.14e+09 1.09e+09 1.13e+09 1.10e+09 ...\n $ source        : chr [1:220] \"ChicEggs-09-23-2016.pdf\" \"ChicEggs-10-21-2016.pdf\" \"ChicEggs-11-22-2016.pdf\" \"ChicEggs-12-23-2016.pdf\" ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nskimr::skim(egg_df_raw)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |egg_df_raw |\n|Number of rows           |220        |\n|Number of columns        |6          |\n|_______________________  |           |\n|Column type frequency:   |           |\n|character                |3          |\n|Date                     |1          |\n|numeric                  |2          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|prod_type     |         0|             1|  10|  13|     0|        2|          0|\n|prod_process  |         0|             1|   3|  23|     0|        3|          0|\n|source        |         0|             1|  23|  23|     0|      108|          0|\n\n\n**Variable type: Date**\n\n|skim_variable  | n_missing| complete_rate|min        |max        |median     | n_unique|\n|:--------------|---------:|-------------:|:----------|:----------|:----------|--------:|\n|observed_month |         0|             1|2016-07-31 |2021-02-28 |2018-11-15 |       56|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|       mean|         sd|        p0|       p25|        p50|        p75|       p100|hist  |\n|:-------------|---------:|-------------:|----------:|----------:|---------:|---------:|----------:|----------:|----------:|:-----|\n|n_hens        |         0|             1|  110839873|  124121204|  13500000|  17284500|   59939500|  125539250|  341166000|▇▁▁▁▂ |\n|n_eggs        |         0|             1| 2606667580| 3082457619| 298074240| 423962023| 1154550000| 2963010996| 8601000000|▇▁▁▁▂ |\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df_raw %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(color = \"blue\") +\n  labs(title = \"US Egg Production\",\n       subtitle = \"December 2007 to February 2021\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n## Cleaning Data\n\nSometimes we like to perform some *preprocessing* of the data.  In this example, we will \n\n* focus on smaller farms where the number of hens is under 100 million\n* `separate` the date into year, month, and day columns\n* turn `prod_process` into a factor variable (helps with R stuff for categorical variables)\n\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df <- egg_df_raw |>\n  filter(n_hens < 1e8) |>\n  separate(observed_month,\n           into = c(\"year\", \"month\", \"day\"),\n           remove = FALSE)\n\negg_df$prod_process <- factor(egg_df$prod_process,\n                              levels = c(\"cage-free (organic)\",\n                                         \"cage-free (non-organic)\",\n                                         \"all\"))\n\n# dimensions\ndim(egg_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 165   9\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(egg_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  observed_month year  month day   prod_type   prod_process n_hens n_eggs source\n  <date>         <chr> <chr> <chr> <chr>       <fct>         <dbl>  <dbl> <chr> \n1 2016-07-31     2016  07    31    hatching e… all          5.80e7 1.15e9 ChicE…\n2 2016-08-31     2016  08    31    hatching e… all          5.76e7 1.14e9 ChicE…\n3 2016-09-30     2016  09    30    hatching e… all          5.72e7 1.09e9 ChicE…\n4 2016-10-31     2016  10    31    hatching e… all          5.69e7 1.13e9 ChicE…\n5 2016-11-30     2016  11    30    hatching e… all          5.71e7 1.10e9 ChicE…\n6 2016-12-31     2016  12    31    hatching e… all          5.77e7 1.13e9 ChicE…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = prod_process),\n             size = 3, alpha = 0.75) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"December 2007 to February 2021\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df %>%\n  ggplot(aes(x = month, y = n_eggs)) +\n  geom_boxplot(aes(fill = month)) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"December 2007 to February 2021\",\n       caption = \"Source: TidyTuesday\",\n       x = \"month\",\n       y = \"number of eggs\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Supervised Learning\n\n* In **supervised learning** has the goal of making predictions with a set of known labels for the response variable.\n\n    * Goal: predict the production type (e.g. cage-free) of each report of the egg data.\n\n* response variable: `prod_process`\n* predictor variables: `n_hens`, `n_eggs`, `month`, `year`, `prod_type`\n* model formula: `prod_process ~ n_hens + n_eggs + month + year + prod_type`\n\n\n::: {.cell}\n\n```{.r .cell-code}\negg_split <- initial_split(egg_df)\negg_train <- training(egg_split)\negg_test  <- testing(egg_split)\n```\n:::\n\n\n\n## Random Forests\n\n“Random forest models are ensembles of decision trees. A large number of decision tree models are created for the ensemble based on slightly different versions of the training set. When creating the individual decision trees, the fitting process encourages them to be as diverse as possible. The collection of trees are combined into the random forest model and, when a new sample is predicted, the votes from each tree are used to calculate the final predicted value for the new sample.” —tidymodels.org\n\n### Define the Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_forest_model <- \n  rand_forest(trees = 250) %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n\n### Fitting the Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_forest_fit <-\n  random_forest_model %>%\n  fit(prod_process ~ n_hens + n_eggs + month + year + prod_type, \n      data = egg_train)\n\nrandom_forest_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~250,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  250 \nSample size:                      123 \nNumber of independent variables:  5 \nMtry:                             2 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.001225525 \n```\n:::\n:::\n\n\n## Visualizing the Forest\n\n(This is an old-fashioned code using the `caret` package, and Derek really should revise his knowledge here.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# OLD-FASHIONED WAY with the caret package\nmodel_rf <- caret::train(prod_process ~ n_hens + n_eggs + month + year + prod_type,\n                         data = egg_train, \n                         method = \"rf\")\nmodel_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom Forest \n\n123 samples\n  5 predictor\n  3 classes: 'cage-free (organic)', 'cage-free (non-organic)', 'all' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 123, 123, 123, 123, 123, 123, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy  Kappa    \n   2    0.99433   0.9914711\n  10    1.00000   1.0000000\n  19    1.00000   1.0000000\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 10.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rpart <- caret::train(prod_process ~ n_hens + n_eggs + month + year + prod_type,\n                         data = egg_train, \n                         method = \"rpart\")\nmodel_rpart\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n123 samples\n  5 predictor\n  3 classes: 'cage-free (organic)', 'cage-free (non-organic)', 'all' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 123, 123, 123, 123, 123, 123, ... \nResampling results across tuning parameters:\n\n  cp        Accuracy   Kappa    \n  0.000000  1.0000000  1.0000000\n  0.474359  0.7759533  0.6646848\n  0.525641  0.5132879  0.2852174\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#source:  https://shiring.github.io/machine_learning/2017/03/16/rf_plot_ggraph\ntree_func <- function(final_model, \n                      tree_num) {\n  \n  # get tree by index\n  tree <- randomForest::getTree(final_model, \n                                k = tree_num, \n                                labelVar = TRUE) %>%\n    tibble::rownames_to_column() %>%\n    # make leaf split points to NA, so the 0s won't get plotted\n    mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))\n  \n  # prepare data frame for graph\n  graph_frame <- data.frame(from = rep(tree$rowname, 2),\n                            to = c(tree$`left daughter`, tree$`right daughter`))\n  \n  # convert to graph and delete the last node that we don't want to plot\n  graph <- graph_from_data_frame(graph_frame) %>%\n    delete_vertices(\"0\")\n  \n  # set node labels\n  V(graph)$node_label <- gsub(\"_\", \" \", as.character(tree$`split var`))\n  V(graph)$leaf_label <- as.character(tree$prediction)\n  V(graph)$split <- as.character(round(tree$`split point`, digits = 2))\n  \n  # plot\n  plot <- ggraph(graph, 'dendrogram') + \n    theme_bw() +\n    geom_edge_link() +\n    geom_node_point() +\n    geom_node_text(aes(label = node_label), na.rm = TRUE, repel = TRUE) +\n    geom_node_label(aes(label = split), vjust = 2.5, na.rm = TRUE, fill = \"white\") +\n    geom_node_label(aes(label = leaf_label, fill = leaf_label), na.rm = TRUE, \n                    repel = TRUE, colour = \"white\", fontface = \"bold\", show.legend = FALSE) +\n    theme(panel.grid.minor = element_blank(),\n          panel.grid.major = element_blank(),\n          panel.background = element_blank(),\n          plot.background = element_rect(fill = \"white\"),\n          panel.border = element_blank(),\n          axis.line = element_blank(),\n          axis.text.x = element_blank(),\n          axis.text.y = element_blank(),\n          axis.ticks = element_blank(),\n          axis.title.x = element_blank(),\n          axis.title.y = element_blank(),\n          plot.title = element_text(size = 18))\n  \n  print(plot)\n}\n\ntree_num <- which.min(model_rf$finalModel$forest$ndbigtree == min(model_rf$finalModel$forest$ndbigtree))\n\ntree_func(final_model = model_rf$finalModel, tree_num)\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n## Classification Error\n\n\n::: {.cell}\n\n```{.r .cell-code}\negg_predictions <- predict(model_rf, newdata = egg_test)\ntable(egg_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\negg_predictions\n    cage-free (organic) cage-free (non-organic)                     all \n                     12                      16                      14 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_1 <- egg_test %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = egg_predictions),\n             size = 3, alpha = 0.75) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"predictions\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nplot_2 <- egg_test %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = prod_process),\n             size = 3, alpha = 0.75) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"true classifications\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n# patchwork\nplot_1 + plot_2\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(egg_predictions, egg_test$prod_process)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n                         Reference\nPrediction                cage-free (organic) cage-free (non-organic) all\n  cage-free (organic)                      10                       2   0\n  cage-free (non-organic)                   0                      16   0\n  all                                       0                       0  14\n\nOverall Statistics\n                                          \n               Accuracy : 0.9524          \n                 95% CI : (0.8384, 0.9942)\n    No Information Rate : 0.4286          \n    P-Value [Acc > NIR] : 5.568e-13       \n                                          \n                  Kappa : 0.9276          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: cage-free (organic) Class: cage-free (non-organic)\nSensitivity                              1.0000                         0.8889\nSpecificity                              0.9375                         1.0000\nPos Pred Value                           0.8333                         1.0000\nNeg Pred Value                           1.0000                         0.9231\nPrevalence                               0.2381                         0.4286\nDetection Rate                           0.2381                         0.3810\nDetection Prevalence                     0.2857                         0.3810\nBalanced Accuracy                        0.9688                         0.9444\n                     Class: all\nSensitivity              1.0000\nSpecificity              1.0000\nPos Pred Value           1.0000\nNeg Pred Value           1.0000\nPrevalence               0.3333\nDetection Rate           0.3333\nDetection Prevalence     0.3333\nBalanced Accuracy        1.0000\n```\n:::\n:::\n\n\n\n## Unsupervised Learning\n\n* In **unsupervised learning**, we try to find structure in the data of the response variable without predetermined labels.\n\n    * Goal: classify farms into groups by size\n\n## K-Means Clustering\n\n### Numerical Variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\negg_numerical <- egg_df |>\n  select(n_hens, n_eggs)\nhead(egg_numerical)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n    n_hens     n_eggs\n     <dbl>      <dbl>\n1 57975000 1147000000\n2 57595000 1142700000\n3 57161000 1093300000\n4 56857000 1126700000\n5 57116000 1096600000\n6 57750000 1132900000\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\negg_numerical %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(color = \"black\") +\n  labs(title = \"US Egg Production\",\n       subtitle = \"How can we organize this data?\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n### First Look\n\nAre there 3 types of chicken farms in the data?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclusters3 <- kmeans(egg_numerical, 3)\n\negg_df_with_clusters <- cbind(egg_numerical, clusters3$cluster)\ncolnames(egg_df_with_clusters) <- c(\"n_hens\", \"n_eggs\", \"cluster\")\n\n# turn cluster from a numerical variable into a factor (categorical) variable\negg_df_with_clusters$cluster <- factor(egg_df_with_clusters$cluster)\n\n# show a sample of observations\negg_df_with_clusters |>\n  slice_sample(n = 10, replace = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     n_hens     n_eggs cluster\n1  14100000  298074240       2\n2  64171000 1212900000       3\n3  27300000  636840617       1\n4  13500000  304762114       2\n5  64955000 1590747994       3\n6  60202000 1120900000       3\n7  17491500  386912160       2\n8  35680000  826794977       1\n9  62135000 1204400000       3\n10 39083000  908679086       1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df_with_clusters %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = cluster),\n             size = 3, alpha = 0.7) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"k = 3 clusters\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n### How to select the number of clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\negg_df_with_clusters %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = cluster),\n             size = 3, alpha = 0.7) +\n  geom_point(aes(x = n_hens, y = n_eggs),\n             color = \"black\",\n             data = data.frame(clusters3$centers), \n             size = 5) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"k = 3 clusters (with centers)\",\n       caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nWe start with an $d$-dimensional data set of numerical variables and prescribe a number $k$ for the number of clusters and run the `kmeans` algorithm.\n\n* Each cluster $C_k$ has $n_k$ points labeled $x_i$ in $d$-dimensional space\n* Each cluster has a cluster center $\\mu_k$\n* Each cluster has a *within-sum-of-squares*\n\n$$\\text{WSS} = \\ds\\sum_{x_{i} \\in C_{k}} (x_i−\\mu_k)^{2}$$\n\nThus, our metric for the clustering will be the reported *total-within-sum-of-squares*\n\n$$\\text{TWSS} = \\ds\\sum_{j=1}^{k}\\sum_{x_{i} \\in C_{k}} (x_i−\\mu_k)^{2}$$\n\n* as the number $k$ of clusters increases, the TWSS decreases\n* but we generally do not want a large number of clusters for later interpretation\n\n### Scree Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk_vals <- 1:9\ntwss <- rep(NA, 9)\n\nfor(k in k_vals){\n  this_clustering <- kmeans(egg_numerical, k)\n  twss[k] <- this_clustering$tot.withinss\n}\n\ndf_analysis <- data.frame(k_vals, twss)\n\ndf_analysis %>%\n  ggplot(aes(x = k_vals, y = twss)) +\n  geom_line() +\n  geom_point(size = 3) +\n  labs(title = \"Scree Plot\",\n       subtitle = \"How many clusters should we pick?\",\n       caption = \"Math 32\",\n       x = \"number of clusters\",\n       y = \"total within sum of squares\") +\n  scale_x_continuous(breaks = 1:9) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n* some advise to pick the “elbow” in the scree plot (where the concavity is greatest)\n* some advise to pick the place where TWSS starts to barely improve\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclusters2 <- kmeans(egg_numerical, 2)\n\negg_df_with_clusters <- cbind(egg_numerical, clusters2$cluster)\ncolnames(egg_df_with_clusters) <- c(\"n_hens\", \"n_eggs\", \"cluster\")\n\n# turn cluster from a numerical variable into a factor (categorical) variable\negg_df_with_clusters$cluster <- factor(egg_df_with_clusters$cluster)\n\nplot_k2 <- egg_df_with_clusters %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = cluster),\n             size = 3, alpha = 0.7) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"k = 2 clusters\",\n       # caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclusters5 <- kmeans(egg_numerical, 5)\n\negg_df_with_clusters <- cbind(egg_numerical, clusters5$cluster)\ncolnames(egg_df_with_clusters) <- c(\"n_hens\", \"n_eggs\", \"cluster\")\n\n# turn cluster from a numerical variable into a factor (categorical) variable\negg_df_with_clusters$cluster <- factor(egg_df_with_clusters$cluster)\n\nplot_k5 <- egg_df_with_clusters %>%\n  ggplot(aes(x = n_hens, y = n_eggs)) +\n  geom_point(aes(color = cluster),\n             size = 3, alpha = 0.7) +\n  labs(title = \"US Egg Production\",\n       subtitle = \"k = 5 clusters\",\n       # caption = \"Source: TidyTuesday\",\n       x = \"number of hens\",\n       y = \"number of eggs\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#patchwork\nplot_k2 + plot_2 + plot_k5\n```\n\n::: {.cell-output-display}\n![](Math_32_35_Machine_Learning_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Math_32_35_Machine_Learning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}